{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 3:\n",
    "    \n",
    "    raise Exception('请使用Python3来完成此项目')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用在ImageNet上训练过的pre-trained model对训练集进行预测，对比预测结果与真实图片是否一致，如否则属异常值\n",
    "\n",
    "pre-trained model输出的是属于猫和狗的种类的概率，狗有118个品种， 猫有7个品种， 如何判断输出结果是猫还是狗呢？\n",
    "\n",
    "- 如某张图的预测结果的Top-N中，既不是‘dogs',也不是'cats'，则认为此图为异常图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cat_breeds = [\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不使用generator的模型，在对多个图片分类时，占用内存太大，速度超级慢，无法实用 ----弃用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def predict_image(MODEL, image_size, preprocess_input, decode_predictions, top_n, image_path):\n",
    "    # using the pre-training weights in ImageNet dataset\n",
    "    base_model = MODEL(weights='imagenet')\n",
    "    \n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "        \n",
    "    preds = base_model.predict(x)\n",
    "    \n",
    "    return decode_predictions(preds, top=top_n)[0]\n",
    "#     print('predicted:', decode_predictions(preds, top=3)[0])\n",
    "    \n",
    "def find_outlier(MODEL, image_size, model_class, model_name):\n",
    "    file_list = os.listdir('train/')\n",
    "    top_N = 20\n",
    "    outlier_files = []\n",
    "    for fname in file_list[:1000]:\n",
    "        fpath = os.path.join('train/', fname)\n",
    "        preds = predict_image(MODEL, image_size, \n",
    "                              model_class.preprocess_input, \n",
    "                              model_class.decode_predictions,\n",
    "                             top_n = top_N,\n",
    "                             image_path=fpath)\n",
    "        print(\"decode pred:\",preds)\n",
    "        \n",
    "        outlier_flag = True\n",
    "        for pet in preds:\n",
    "            if pet[0] in dog_breeds or pet[0] in cat_breeds:\n",
    "                outlier_flag = False\n",
    "                break;\n",
    "        \n",
    "        # 检查预测概率最高的品种是否错误\n",
    "        if outlier_flag == False:\n",
    "            pet = preds[0]\n",
    "            if pet[2] > 0.6:\n",
    "                if pet[0] in dog_breeds and fname[:3] == 'cat': # 指猫为'dog'\n",
    "                    outlier_flag = True\n",
    "                    print(\"Cat is not Dog\")\n",
    "                    \n",
    "                if pet[0] in cat_breeds and fname[:3] == 'dog':\n",
    "                    outlier_flag = True\n",
    "                    print(\"Dos is not cat\")\n",
    "                \n",
    "        if outlier_flag:\n",
    "            outlier_files.append(fname)\n",
    "            print('%s is a outlier !' %fname)\n",
    "    \n",
    "    # save the outlier to file\n",
    "    out_filename = 'outlier/' + model_name + \".txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(outlier_files))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于生成器的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对指定文件夹内的图片分类，结果存入h5文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode_preds size: 8\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ResNet50\"\n",
    "def read_decode_preds_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "decode_preds = read_decode_preds_from_file('outlier/' + model_name + \"_decodepreds.txt\")\n",
    "\n",
    "print('decode_preds size:', len(decode_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_in_decode_preds(model_name, decode_preds_set, filenames):\n",
    "    outlier_files = []\n",
    "    file_id = 0\n",
    "    for index,decode_pred in enumerate(decode_preds_set):\n",
    "        fname = filenames[index]\n",
    "#         print(\"file name:\", fname[6:9])\n",
    "        ## 1st, if no dog and cat in Top-N of this prediction, this impage is a outlier\n",
    "        outlier_flag = True\n",
    "        for pet in decode_pred:\n",
    "            if pet[0] in dog_breeds or pet[0] in cat_breeds:\n",
    "                outlier_flag = False\n",
    "                break;\n",
    "        \n",
    "        ## 2nd: 检查预测概率最高的品种是否错误\n",
    "        if outlier_flag:\n",
    "            print(\"%s is not Dog or Cat\" %fname)\n",
    "        else:\n",
    "            pet = decode_pred[0]\n",
    "            if pet[2] > 0.3:\n",
    "                if pet[0] in dog_breeds and fname[6:9] == 'dog': # 指猫为'dog'\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not cat\" %fname)\n",
    "                    \n",
    "                if pet[0] in cat_breeds and fname[6:9] == 'dog':\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not dog\" %fname)\n",
    "                \n",
    "        if outlier_flag:\n",
    "            outlier_files.append(fname[6:])\n",
    "#             print('%s is a outlier !' %fname)\n",
    "    \n",
    "    # save the outlier to file\n",
    "    out_filename = 'outlier/' + model_name + \"_outliers.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(outlier_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n",
      "train/dog.0.jpg is not cat\n",
      "train/dog.5.jpg is not cat\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import *\n",
    "\n",
    "image_gen = ImageDataGenerator()\n",
    "train_generator = image_gen.flow_from_directory('pending-clean', \n",
    "                                                target_size=(224,224), \n",
    "                                                shuffle=False, # our data will be in order\n",
    "                                                batch_size=16,\n",
    "                                                class_mode=None)\n",
    "\n",
    "find_outlier_in_decode_preds(\"ResNet50\", decode_preds, train_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate the top-N accuracy sum inp predictions\n",
    "def read_decode_preds_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def display_top_n_acc_sum(pred):\n",
    "    acc_sum = 0.0\n",
    "    for pet in pred:\n",
    "        acc_sum += pet[2]\n",
    "        \n",
    "    print('top-N accuracy sum:', acc_sum)\n",
    "\n",
    "def show_all_preditions_top_n(decode_preds):\n",
    "    for d_pred in decode_preds:\n",
    "        display_top_n_acc_sum(d_pred)\n",
    "        \n",
    "model_name = 'ResNet50'\n",
    "decode_preds = read_decode_preds_from_file('outlier/' + model_name + \"_decodepreds.txt\")\n",
    "print(\"model:\", model_name)\n",
    "show_all_preditions_top_n(decode_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "predicts shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import h5py\n",
    "\n",
    "def find_outliers(MODEL, image_size, model_class, model_name):\n",
    "    image_gen = ImageDataGenerator()\n",
    "    train_generator = image_gen.flow_from_directory('out_train', \n",
    "                                                target_size=image_size, \n",
    "                                                shuffle=False, # our data will be in order\n",
    "                                                batch_size=16,\n",
    "                                                class_mode=None)\n",
    "    \n",
    "    ## use pre-trained model to get features from image generator\n",
    "    x = Input((image_size[0], image_size[1], 3)) # shape: width, height, channel\n",
    "    ## 此处必须使用匿名函数, 要让 preprocess_input 在predict_generator时再运行， 而不是在此处\n",
    "    lambda x:model_class.preprocess_input(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet')\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    \n",
    "    # the predict_generator method returns the output of a model, given\n",
    "    # a generator that yields batches of numpy data\n",
    "    preds = model.predict_generator(train_generator, verbose=1)\n",
    "    \n",
    "    print(\"predicts shape:\", preds.shape)\n",
    "    \n",
    "    # save the output to h5 file\n",
    "#     out_filename = 'outlier/' + model_name + \"_preds.h5\"\n",
    "#     with h5py.File(out_filename,'w') as h:\n",
    "#         h.create_dataset(\"preds\", data=preds)\n",
    "    \n",
    "    top_N = 20\n",
    "    decode_preds = model_class.decode_predictions(preds, top=top_N)\n",
    "\n",
    "    out_filename = 'outlier/' + model_name + \"_decodepreds.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(decode_preds))\n",
    "        \n",
    "    find_outlier_in_decode_preds(model_name, decode_preds, train_generator.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode pred: [('n02124075', 'Egyptian_cat', 0.56555563), ('n02123045', 'tabby', 0.28696027), ('n02127052', 'lynx', 0.051270023), ('n02123159', 'tiger_cat', 0.035105415), ('n04209239', 'shower_curtain', 0.012346651), ('n02808440', 'bathtub', 0.0040852465), ('n02971356', 'carton', 0.0040702336), ('n04589890', 'window_screen', 0.003119407), ('n03958227', 'plastic_bag', 0.0023623363), ('n04493381', 'tub', 0.0022657104), ('n02808304', 'bath_towel', 0.0019139963), ('n02325366', 'wood_rabbit', 0.0017331188), ('n02114855', 'coyote', 0.0016469031), ('n02326432', 'hare', 0.0014933287), ('n04553703', 'washbasin', 0.0013880422), ('n02120505', 'grey_fox', 0.0011291141), ('n02909870', 'bucket', 0.0010200642), ('n04070727', 'refrigerator', 0.0009789072), ('n03223299', 'doormat', 0.00089990476), ('n03443371', 'goblet', 0.00082443375)]\n",
      "decode pred: [('n02123045', 'tabby', 0.73149043), ('n02123159', 'tiger_cat', 0.19419812), ('n02124075', 'Egyptian_cat', 0.019166976), ('n02127052', 'lynx', 0.019048095), ('n02123394', 'Persian_cat', 0.010066337), ('n02129604', 'tiger', 0.0020342772), ('n02128385', 'leopard', 0.00096953596), ('n03958227', 'plastic_bag', 0.00085133844), ('n04367480', 'swab', 0.00084386586), ('n03325584', 'feather_boa', 0.0005885958), ('n03598930', 'jigsaw_puzzle', 0.00044283835), ('n03085013', 'computer_keyboard', 0.00041691688), ('n02939185', 'caldron', 0.00038434236), ('n02971356', 'carton', 0.0003781957), ('n04589890', 'window_screen', 0.00032785), ('n02128757', 'snow_leopard', 0.0002908884), ('n03942813', 'ping-pong_ball', 0.00028583832), ('n13133613', 'ear', 0.00027895486), ('n04074963', 'remote_control', 0.00027642434), ('n03223299', 'doormat', 0.00027587154)]\n",
      "is cat not dog\n",
      "cat.898.jpg is a outlier !\n"
     ]
    }
   ],
   "source": [
    "find_outlier(resnet50.ResNet50, (224,224), resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 98s 63ms/step\n",
      "782/782 [==============================] - 49s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "find_outlier(xception.Xception, (299,299), xception.preprocess_input, \"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outlier(inception_resnet_v2.InceptionResNetV2, (299,299), inception_resnet_v2.preprocess_input,\"InceptionResNetV2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剔除异常值\n",
    "\n",
    "把'train/'图片复制到'clear-train/', 把outlier list中的文件从'clear-train/'中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_outliers_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "# outlier_files = []\n",
    "# outlier_files += read_outliers_from_file('outlier/ResNet50.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/Xception.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/InceptionResNetV2.txt')\n",
    "# print(outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def clean_data(old_dir, clean_dir, outlier_list):\n",
    "    if os.path.exists(clean_dir):\n",
    "        shutil.rmtree(clean_dir)\n",
    "    os.mkdir(clean_dir)\n",
    "    \n",
    "    file_list = os.listdir(old_dir)\n",
    "    for filename in file_list:\n",
    "        if filename not in outlier_list:\n",
    "            os.symlink('../'+old_dir+filename, clean_dir+filename)\n",
    "    \n",
    "    print('clean over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean over\n"
     ]
    }
   ],
   "source": [
    "clean_data('train/', 'clean-train/', outlier_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从各pre-trained model生成的outlier list中筛选出真正的outlier\n",
    "\n",
    "筛选原理：如某张图片在所有model的outlier list中都存在，则认为该图为outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real outliers: {'cat.7564.jpg', 'cat.11184.jpg', 'cat.10712.jpg', 'dog.10237.jpg', 'dog.8736.jpg', 'cat.8456.jpg', 'dog.10801.jpg', 'dog.2614.jpg', 'cat.8990.jpg', 'cat.10029.jpg', 'dog.12376.jpg', 'dog.5604.jpg', 'dog.4367.jpg', 'dog.10161.jpg', 'cat.3300.jpg', 'cat.5418.jpg', 'dog.6475.jpg'}\n"
     ]
    }
   ],
   "source": [
    "models_name = ['ResNet50', 'Xception', 'InceptionV3', 'InceptionResNetV2']\n",
    "\n",
    "model_outliers = []\n",
    "for idx in range(len(models_name)):\n",
    "    fname = 'outlier/' + models_name[idx] + '_outliers.txt'\n",
    "    model_outliers.append(set(read_outliers_from_file(fname)))\n",
    "    \n",
    "real_outliers = model_outliers[0]\n",
    "for i in range(1,3):\n",
    "    real_outliers &= model_outliers[i]\n",
    "    \n",
    "print('real outliers:', real_outliers)\n",
    "\n",
    "wfielname = \"outlier/real_outliers.txt\"\n",
    "with open(wfielname,'w') as f:\n",
    "        f.write(str(real_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier file: cat.7564.jpg\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "symbolic link privilege not held",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8e5b71a974f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreal_outliers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outlier file:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../train/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'outlier/image/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m: symbolic link privilege not held"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "## copy real outlier to outlier/image/\n",
    "if os.path.exists('outlier/image'):\n",
    "    shutil.rmtree('outlier/image')\n",
    "os.mkdir('outlier/image')\n",
    "\n",
    "for filen in real_outliers:\n",
    "    print('outlier file:', filen)\n",
    "    os.symlink('../../train/'+filen, 'outlier/image/'+filen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
