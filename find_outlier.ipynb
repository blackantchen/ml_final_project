{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 3:\n",
    "    \n",
    "    raise Exception('请使用Python3来完成此项目')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用在ImageNet上训练过的pre-trained model对训练集进行预测，对比预测结果与真实图片是否一致，如否则属异常值\n",
    "\n",
    "pre-trained model输出的是属于猫和狗的种类的概率，狗有118个品种， 猫有7个品种， 如何判断输出结果是猫还是狗呢？\n",
    "\n",
    "- 如某张图的预测结果的Top-N中，既不是‘dogs',也不是'cats'，则认为此图为异常图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cat_breeds = [\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件夹结构\n",
    "\n",
    "--train/\n",
    "--test/\n",
    "\n",
    "--pending-clean/\n",
    "\n",
    "      |--train   指向train的软连接\n",
    "      \n",
    "--clean-train 清理过train\n",
    "\n",
    "\n",
    "**定义文件夹名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_clean_dir = 'pending-clean'\n",
    "cleaned_dir = 'clean-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "## create folders: outlier-train, clearn-train\n",
    "def create_new_dir(new_dir):\n",
    "    if os.path.exists(new_dir):\n",
    "        shutil.rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "create_new_dir(pending_clean_dir)\n",
    "create_new_dir(cleaned_dir)\n",
    "\n",
    "os.symlink('../train', pending_clean_dir+'/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于生成器的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对指定文件夹内的图片分类，如预测结果与标签不符，则列入outlier_list并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_in_decode_preds(model_name, decode_preds_set, filenames):\n",
    "    outlier_files = []\n",
    "    file_id = 0\n",
    "    for index,decode_pred in enumerate(decode_preds_set):\n",
    "        fname = filenames[index]\n",
    "        \n",
    "        ## 1st, if no dog and cat in Top-N of this prediction, this impage is a outlier\n",
    "        outlier_flag = True\n",
    "        for pet in decode_pred:\n",
    "            if pet[0] in dog_breeds or pet[0] in cat_breeds:\n",
    "                outlier_flag = False\n",
    "                break;\n",
    "        \n",
    "        ## 2nd: 检查预测概率最高的品种是否错误\n",
    "        if outlier_flag:\n",
    "            print(\"%s is not Dog or Cat\" %fname)\n",
    "        else:\n",
    "            pet = decode_pred[0]\n",
    "            if pet[2] > 0.7:\n",
    "                if pet[0] in dog_breeds and fname[:3] == 'cat': # 指猫为'dog'\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not cat\" %fname)\n",
    "                    \n",
    "                if pet[0] in cat_breeds and fname[:3] == 'dog':\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not dog\" %fname)\n",
    "                \n",
    "        if outlier_flag:\n",
    "            outlier_files.append(fname)\n",
    "#             print('%s is a outlier !' %fname)\n",
    "    \n",
    "    # save the outlier to file\n",
    "    out_filename = 'outlier/' + model_name + \"_outliers.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(outlier_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import h5py\n",
    "\n",
    "def find_outliers(MODEL, image_size, model_class, model_name):\n",
    "    #------\n",
    "    top_N = 25\n",
    "    #------\n",
    "    # create ImageDataGenerator, and indicate \"preprocessing_functions\"\n",
    "    image_gen = ImageDataGenerator(preprocessing_function=model_class.preprocess_input)\n",
    "    \n",
    "    train_generator = image_gen.flow_from_directory('out_train', \n",
    "                                                target_size=image_size, \n",
    "                                                shuffle=False, # our data will be in order\n",
    "                                                batch_size=16,\n",
    "                                                class_mode=None)\n",
    "    \n",
    "    ## use pre-trained model to get features from image generator\n",
    "    x = Input((image_size[0], image_size[1], 3)) # shape: width, height, channel\n",
    "    ## 下面这种直接定义lambda的方式在keras模型中是错误的，keras.layers中有专门的一个层 layers.Lambda 来代替\n",
    "#     lambda x:model_class.preprocess_input(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet')\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    \n",
    "    # the predict_generator method returns the output of a model, given\n",
    "    # a generator that yields batches of numpy data\n",
    "    preds = model.predict_generator(train_generator, verbose=1)\n",
    "    \n",
    "    print(\"predicts shape:\", preds.shape)\n",
    "    \n",
    "    # save the output to h5 file\n",
    "#     out_filename = 'outlier/' + model_name + \"_preds.h5\"\n",
    "#     with h5py.File(out_filename,'w') as h:\n",
    "#         h.create_dataset(\"preds\", data=preds)\n",
    "    \n",
    "    decode_preds = model_class.decode_predictions(preds, top=top_N)\n",
    "\n",
    "    out_filename = 'outlier/' + model_name + \"_decodepreds.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(decode_preds))\n",
    "        \n",
    "    find_outlier_in_decode_preds(model_name, decode_preds, train_generator.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "predicts shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "find_outliers(resnet50.ResNet50, (224,224), resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "predicts shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "find_outliers(xception.Xception, (299,299), xception, \"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "predicts shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "find_outliers(inception_v3.InceptionV3, (299,299), inception_v3, \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 1 classes.\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "predicts shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "find_outliers(inception_resnet_v2.InceptionResNetV2, (299,299), inception_resnet_v2,\"InceptionResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Xception\n",
      "top-N accuracy sum: 0.87281270204\n",
      "top-N accuracy sum: 0.9133912140699999\n",
      "top-N accuracy sum: 0.9748157333499999\n",
      "top-N accuracy sum: 0.8091200223999998\n",
      "top-N accuracy sum: 0.6504523473\n"
     ]
    }
   ],
   "source": [
    "# caculate the top-N accuracy sum inp predictions\n",
    "def read_decode_preds_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def display_top_n_acc_sum(pred):\n",
    "    acc_sum = 0.0\n",
    "    for pet in pred:\n",
    "        acc_sum += pet[2]\n",
    "        \n",
    "    print('top-N accuracy sum:', acc_sum)\n",
    "\n",
    "def show_all_preditions_top_n(decode_preds):\n",
    "    for d_pred in decode_preds:\n",
    "        display_top_n_acc_sum(d_pred)\n",
    "        \n",
    "model_name = 'Xception'\n",
    "decode_preds = read_decode_preds_from_file('outlier/' + model_name + \"_decodepreds.txt\")\n",
    "print(\"model:\", model_name)\n",
    "show_all_preditions_top_n(decode_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剔除异常值\n",
    "\n",
    "把'pre-train/'图片复制到'clear-train/', 把outlier list中的文件从'clear-train/'中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat/cat.19.jpg']\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ResNet50'\n",
    "def read_outliers_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "filename = 'outlier/' + model_name + \"_outliers.txt\"\n",
    "outlier_files = []\n",
    "outlier_files += read_outliers_from_file(filename)\n",
    "# outlier_files += read_outliers_from_file('outlier/Xception.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/InceptionResNetV2.txt')\n",
    "print(outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def clean_data(old_dir, clean_dir, outlier_list):\n",
    "    if os.path.exists(clean_dir):\n",
    "        shutil.rmtree(clean_dir)\n",
    "    os.mkdir(clean_dir)\n",
    "    \n",
    "#     file_list = os.listdir(old_dir)\n",
    "#     for filename in file_list:\n",
    "#         os.symlink('../'+old_dir+filename, clean_dir+filename)\n",
    "    \n",
    "    os.symlink('../test', 'pre-test/test')\n",
    "    \n",
    "    for filename in outlier_list:\n",
    "        os.remove(clean_dir+filename)\n",
    "    print('clean over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean over\n"
     ]
    }
   ],
   "source": [
    "clean_data('out_train/', 'clean-train/', outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
