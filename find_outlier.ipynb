{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 3:\n",
    "    \n",
    "    raise Exception('请使用Python3来完成此项目')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用在ImageNet上训练过的pre-trained model对训练集进行预测，对比预测结果与真实图片是否一致，如否则属异常值\n",
    "\n",
    "pre-trained model输出的是属于猫和狗的种类的概率，狗有118个品种， 猫有7个品种， 如何判断输出结果是猫还是狗呢？\n",
    "\n",
    "- 如某张图的预测结果的Top-N中，既不是‘dogs',也不是'cats'，则认为此图为异常图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cat_breeds = [\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件夹结构\n",
    "\n",
    "--train/\n",
    "--test/\n",
    "\n",
    "--pending-clean/\n",
    "\n",
    "      |--train   指向train的软连接\n",
    "      \n",
    "--clean-train 清理过train\n",
    "\n",
    "\n",
    "**定义文件夹名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_clean_dir = 'pending-clean'\n",
    "cleaned_dir = 'clean-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "## create folders: outlier-train, clearn-train\n",
    "def create_new_dir(new_dir):\n",
    "    if os.path.exists(new_dir):\n",
    "        shutil.rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "create_new_dir(pending_clean_dir)\n",
    "create_new_dir(cleaned_dir)\n",
    "\n",
    "os.symlink('../train', pending_clean_dir+'/train') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于生成器的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对指定文件夹内的图片分类，如预测结果与标签不符，则列入outlier_list并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_in_decode_preds(model_name, decode_preds_set, filenames):\n",
    "    outlier_files = []\n",
    "    file_id = 0\n",
    "    for index,decode_pred in enumerate(decode_preds_set):\n",
    "        fname = filenames[index]\n",
    "#         print(\"file name:\", fname)\n",
    "        ## 1st, if no dog and cat in Top-N of this prediction, this impage is a outlier\n",
    "        outlier_flag = True\n",
    "        for pet in decode_pred:\n",
    "            if pet[0] in dog_breeds or pet[0] in cat_breeds:\n",
    "                outlier_flag = False\n",
    "                break;\n",
    "        \n",
    "        ## 2nd: 检查预测概率最高的品种是否错误\n",
    "        if outlier_flag:\n",
    "            print(\"%s is not Dog or Cat\" %fname)\n",
    "        else:\n",
    "            pet = decode_pred[0]\n",
    "            if pet[2] > 0.7:\n",
    "                if pet[0] in dog_breeds and fname[6:9] == 'cat': # 指猫为'dog'\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not cat\" %fname)\n",
    "                    \n",
    "                if pet[0] in cat_breeds and fname[6:9] == 'dog':\n",
    "                    outlier_flag = True\n",
    "                    print(\"%s is not dog\" %fname)\n",
    "                \n",
    "        if outlier_flag:\n",
    "            outlier_files.append(fname[6:])\n",
    "#             print('%s is a outlier !' %fname)\n",
    "    \n",
    "    # save the outlier to file\n",
    "    out_filename = 'outlier/' + model_name + \"_outliers.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(outlier_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import h5py\n",
    "\n",
    "def find_outliers(MODEL, image_size, model_class, model_name):\n",
    "    #------\n",
    "    top_N = 50\n",
    "    #------\n",
    "    # create ImageDataGenerator, and indicate \"preprocessing_functions\"\n",
    "    image_gen = ImageDataGenerator(preprocessing_function=model_class.preprocess_input)\n",
    "    \n",
    "    train_generator = image_gen.flow_from_directory(pending_clean_dir, \n",
    "                                                target_size=image_size, \n",
    "                                                shuffle=False, # our data will be in order\n",
    "                                                batch_size=16,\n",
    "                                                class_mode=None)\n",
    "    \n",
    "    ## use pre-trained model to get features from image generator\n",
    "    x = Input((image_size[0], image_size[1], 3)) # shape: width, height, channel\n",
    "    ## 下面这种直接定义lambda的方式在keras模型中是错误的，keras.layers中有专门的一个层 layers.Lambda 来代替\n",
    "#     lambda x:model_class.preprocess_input(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet')\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    \n",
    "    # the predict_generator method returns the output of a model, given\n",
    "    # a generator that yields batches of numpy data\n",
    "    preds = model.predict_generator(train_generator, verbose=1)\n",
    "    \n",
    "    print(\"predicts shape:\", preds.shape)\n",
    "    \n",
    "    # save the output to h5 file\n",
    "#     out_filename = 'outlier/' + model_name + \"_preds.h5\"\n",
    "#     with h5py.File(out_filename,'w') as h:\n",
    "#         h.create_dataset(\"preds\", data=preds)\n",
    "    \n",
    "    decode_preds = model_class.decode_predictions(preds, top=top_N)\n",
    "\n",
    "    out_filename = 'outlier/' + model_name + \"_decodepreds.txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(decode_preds))\n",
    "        \n",
    "    find_outlier_in_decode_preds(model_name, decode_preds, train_generator.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 96s 61ms/step\n",
      "predicts shape: (25000, 1000)\n",
      "train/cat.10029.jpg is not Dog or Cat\n",
      "train/cat.1007.jpg is not cat\n",
      "train/cat.10107.jpg is not cat\n",
      "train/cat.10283.jpg is not cat\n",
      "train/cat.10326.jpg is not cat\n",
      "train/cat.10327.jpg is not cat\n",
      "train/cat.10365.jpg is not Dog or Cat\n",
      "train/cat.10536.jpg is not Dog or Cat\n",
      "train/cat.10712.jpg is not Dog or Cat\n",
      "train/cat.10794.jpg is not cat\n",
      "train/cat.1088.jpg is not cat\n",
      "train/cat.11039.jpg is not Dog or Cat\n",
      "train/cat.11044.jpg is not cat\n",
      "train/cat.11062.jpg is not cat\n",
      "train/cat.11075.jpg is not cat\n",
      "train/cat.11118.jpg is not cat\n",
      "train/cat.11184.jpg is not Dog or Cat\n",
      "train/cat.11228.jpg is not cat\n",
      "train/cat.11243.jpg is not cat\n",
      "train/cat.1139.jpg is not Dog or Cat\n",
      "train/cat.11420.jpg is not cat\n",
      "train/cat.11606.jpg is not cat\n",
      "train/cat.11667.jpg is not cat\n",
      "train/cat.11684.jpg is not cat\n",
      "train/cat.11690.jpg is not cat\n",
      "train/cat.11717.jpg is not cat\n",
      "train/cat.11870.jpg is not cat\n",
      "train/cat.12025.jpg is not cat\n",
      "train/cat.1210.jpg is not cat\n",
      "train/cat.12272.jpg is not Dog or Cat\n",
      "train/cat.12341.jpg is not cat\n",
      "train/cat.1245.jpg is not cat\n",
      "train/cat.12476.jpg is not Dog or Cat\n",
      "train/cat.12481.jpg is not cat\n",
      "train/cat.134.jpg is not cat\n",
      "train/cat.1417.jpg is not cat\n",
      "train/cat.1742.jpg is not cat\n",
      "train/cat.1841.jpg is not cat\n",
      "train/cat.1867.jpg is not cat\n",
      "train/cat.2021.jpg is not cat\n",
      "train/cat.2150.jpg is not cat\n",
      "train/cat.2258.jpg is not cat\n",
      "train/cat.23.jpg is not cat\n",
      "train/cat.2402.jpg is not cat\n",
      "train/cat.2505.jpg is not cat\n",
      "train/cat.2520.jpg is not Dog or Cat\n",
      "train/cat.2587.jpg is not cat\n",
      "train/cat.2621.jpg is not cat\n",
      "train/cat.2939.jpg is not Dog or Cat\n",
      "train/cat.2948.jpg is not cat\n",
      "train/cat.3176.jpg is not cat\n",
      "train/cat.318.jpg is not cat\n",
      "train/cat.3300.jpg is not cat\n",
      "train/cat.3398.jpg is not cat\n",
      "train/cat.359.jpg is not cat\n",
      "train/cat.3672.jpg is not Dog or Cat\n",
      "train/cat.3699.jpg is not cat\n",
      "train/cat.3713.jpg is not cat\n",
      "train/cat.3748.jpg is not cat\n",
      "train/cat.3787.jpg is not cat\n",
      "train/cat.3880.jpg is not cat\n",
      "train/cat.4030.jpg is not cat\n",
      "train/cat.4053.jpg is not cat\n",
      "train/cat.4087.jpg is not cat\n",
      "train/cat.4126.jpg is not cat\n",
      "train/cat.4154.jpg is not cat\n",
      "train/cat.4225.jpg is not cat\n",
      "train/cat.4308.jpg is not Dog or Cat\n",
      "train/cat.4405.jpg is not cat\n",
      "train/cat.4442.jpg is not cat\n",
      "train/cat.4500.jpg is not cat\n",
      "train/cat.4551.jpg is not cat\n",
      "train/cat.4575.jpg is not cat\n",
      "train/cat.4688.jpg is not Dog or Cat\n",
      "train/cat.4950.jpg is not cat\n",
      "train/cat.4965.jpg is not cat\n",
      "train/cat.4967.jpg is not cat\n",
      "train/cat.5018.jpg is not cat\n",
      "train/cat.5070.jpg is not cat\n",
      "train/cat.5170.jpg is not cat\n",
      "train/cat.5325.jpg is not cat\n",
      "train/cat.5418.jpg is not Dog or Cat\n",
      "train/cat.5536.jpg is not cat\n",
      "train/cat.5583.jpg is not cat\n",
      "train/cat.5610.jpg is not cat\n",
      "train/cat.5623.jpg is not cat\n",
      "train/cat.5968.jpg is not cat\n",
      "train/cat.5974.jpg is not Dog or Cat\n",
      "train/cat.5987.jpg is not cat\n",
      "train/cat.6276.jpg is not cat\n",
      "train/cat.6277.jpg is not cat\n",
      "train/cat.6337.jpg is not cat\n",
      "train/cat.6348.jpg is not Dog or Cat\n",
      "train/cat.6618.jpg is not cat\n",
      "train/cat.6628.jpg is not cat\n",
      "train/cat.6751.jpg is not cat\n",
      "train/cat.6973.jpg is not cat\n",
      "train/cat.7047.jpg is not cat\n",
      "train/cat.7057.jpg is not cat\n",
      "train/cat.7130.jpg is not cat\n",
      "train/cat.717.jpg is not cat\n",
      "train/cat.7296.jpg is not cat\n",
      "train/cat.7371.jpg is not cat\n",
      "train/cat.7377.jpg is not Dog or Cat\n",
      "train/cat.7382.jpg is not cat\n",
      "train/cat.7416.jpg is not cat\n",
      "train/cat.7418.jpg is not cat\n",
      "train/cat.7429.jpg is not cat\n",
      "train/cat.7458.jpg is not cat\n",
      "train/cat.7520.jpg is not cat\n",
      "train/cat.7564.jpg is not Dog or Cat\n",
      "train/cat.7580.jpg is not cat\n",
      "train/cat.7603.jpg is not cat\n",
      "train/cat.7612.jpg is not cat\n",
      "train/cat.7650.jpg is not cat\n",
      "train/cat.7678.jpg is not cat\n",
      "train/cat.7685.jpg is not cat\n",
      "train/cat.7947.jpg is not cat\n",
      "train/cat.8149.jpg is not cat\n",
      "train/cat.8189.jpg is not cat\n",
      "train/cat.8350.jpg is not cat\n",
      "train/cat.8456.jpg is not Dog or Cat\n",
      "train/cat.8470.jpg is not Dog or Cat\n",
      "train/cat.8501.jpg is not cat\n",
      "train/cat.8504.jpg is not cat\n",
      "train/cat.8601.jpg is not cat\n",
      "train/cat.8860.jpg is not cat\n",
      "train/cat.8921.jpg is not Dog or Cat\n",
      "train/cat.8935.jpg is not cat\n",
      "train/cat.8957.jpg is not cat\n",
      "train/cat.8978.jpg is not cat\n",
      "train/cat.8990.jpg is not cat\n",
      "train/cat.9006.jpg is not cat\n",
      "train/cat.906.jpg is not cat\n",
      "train/cat.9366.jpg is not cat\n",
      "train/cat.9407.jpg is not cat\n",
      "train/cat.9490.jpg is not cat\n",
      "train/cat.9524.jpg is not cat\n",
      "train/cat.9592.jpg is not cat\n",
      "train/cat.9890.jpg is not cat\n",
      "train/cat.9918.jpg is not cat\n",
      "train/cat.9983.jpg is not Dog or Cat\n",
      "train/dog.10161.jpg is not Dog or Cat\n",
      "train/dog.10237.jpg is not Dog or Cat\n",
      "train/dog.10801.jpg is not Dog or Cat\n",
      "train/dog.11299.jpg is not Dog or Cat\n",
      "train/dog.11437.jpg is not Dog or Cat\n",
      "train/dog.1194.jpg is not Dog or Cat\n",
      "train/dog.12376.jpg is not Dog or Cat\n",
      "train/dog.1625.jpg is not Dog or Cat\n",
      "train/dog.1773.jpg is not Dog or Cat\n",
      "train/dog.2339.jpg is not Dog or Cat\n",
      "train/dog.2422.jpg is not Dog or Cat\n",
      "train/dog.2614.jpg is not Dog or Cat\n",
      "train/dog.4218.jpg is not Dog or Cat\n",
      "train/dog.4367.jpg is not Dog or Cat\n",
      "train/dog.4507.jpg is not Dog or Cat\n",
      "train/dog.4768.jpg is not dog\n",
      "train/dog.5604.jpg is not Dog or Cat\n",
      "train/dog.6475.jpg is not Dog or Cat\n",
      "train/dog.6725.jpg is not Dog or Cat\n",
      "train/dog.7076.jpg is not Dog or Cat\n",
      "train/dog.7706.jpg is not Dog or Cat\n",
      "train/dog.8736.jpg is not Dog or Cat\n",
      "train/dog.9517.jpg is not Dog or Cat\n",
      "train/dog.9761.jpg is not dog\n"
     ]
    }
   ],
   "source": [
    "find_outliers(resnet50.ResNet50, (224,224), resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 112s 72ms/step\n",
      "predicts shape: (25000, 1000)\n",
      "train/cat.10029.jpg is not Dog or Cat\n",
      "train/cat.10139.jpg is not cat\n",
      "train/cat.10636.jpg is not Dog or Cat\n",
      "train/cat.10712.jpg is not Dog or Cat\n",
      "train/cat.10794.jpg is not cat\n",
      "train/cat.10864.jpg is not cat\n",
      "train/cat.11184.jpg is not Dog or Cat\n",
      "train/cat.11420.jpg is not cat\n",
      "train/cat.1145.jpg is not cat\n",
      "train/cat.11475.jpg is not cat\n",
      "train/cat.12341.jpg is not cat\n",
      "train/cat.12424.jpg is not Dog or Cat\n",
      "train/cat.12476.jpg is not Dog or Cat\n",
      "train/cat.1779.jpg is not cat\n",
      "train/cat.2817.jpg is not cat\n",
      "train/cat.3216.jpg is not Dog or Cat\n",
      "train/cat.326.jpg is not cat\n",
      "train/cat.3300.jpg is not cat\n",
      "train/cat.3672.jpg is not Dog or Cat\n",
      "train/cat.4338.jpg is not Dog or Cat\n",
      "train/cat.4637.jpg is not cat\n",
      "train/cat.4688.jpg is not Dog or Cat\n",
      "train/cat.5071.jpg is not Dog or Cat\n",
      "train/cat.5418.jpg is not Dog or Cat\n",
      "train/cat.5698.jpg is not cat\n",
      "train/cat.5813.jpg is not cat\n",
      "train/cat.587.jpg is not cat\n",
      "train/cat.5911.jpg is not cat\n",
      "train/cat.5914.jpg is not cat\n",
      "train/cat.6007.jpg is not cat\n",
      "train/cat.6337.jpg is not cat\n",
      "train/cat.6442.jpg is not cat\n",
      "train/cat.7377.jpg is not Dog or Cat\n",
      "train/cat.7458.jpg is not cat\n",
      "train/cat.7564.jpg is not Dog or Cat\n",
      "train/cat.7599.jpg is not cat\n",
      "train/cat.7957.jpg is not cat\n",
      "train/cat.7968.jpg is not Dog or Cat\n",
      "train/cat.8456.jpg is not Dog or Cat\n",
      "train/cat.856.jpg is not cat\n",
      "train/cat.8647.jpg is not cat\n",
      "train/cat.8990.jpg is not cat\n",
      "train/cat.9082.jpg is not cat\n",
      "train/cat.9171.jpg is not Dog or Cat\n",
      "train/cat.9642.jpg is not cat\n",
      "train/cat.9651.jpg is not cat\n",
      "train/dog.10161.jpg is not Dog or Cat\n",
      "train/dog.10190.jpg is not Dog or Cat\n",
      "train/dog.10237.jpg is not Dog or Cat\n",
      "train/dog.10801.jpg is not Dog or Cat\n",
      "train/dog.11299.jpg is not Dog or Cat\n",
      "train/dog.12376.jpg is not Dog or Cat\n",
      "train/dog.1259.jpg is not Dog or Cat\n",
      "train/dog.1895.jpg is not Dog or Cat\n",
      "train/dog.2614.jpg is not Dog or Cat\n",
      "train/dog.3889.jpg is not Dog or Cat\n",
      "train/dog.4367.jpg is not Dog or Cat\n",
      "train/dog.5604.jpg is not Dog or Cat\n",
      "train/dog.6475.jpg is not Dog or Cat\n",
      "train/dog.8736.jpg is not Dog or Cat\n",
      "train/dog.8898.jpg is not Dog or Cat\n",
      "train/dog.9188.jpg is not Dog or Cat\n",
      "train/dog.9517.jpg is not Dog or Cat\n"
     ]
    }
   ],
   "source": [
    "find_outliers(xception.Xception, (299,299), xception, \"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 108s 69ms/step\n",
      "predicts shape: (25000, 1000)\n",
      "train/cat.10029.jpg is not Dog or Cat\n",
      "train/cat.10099.jpg is not cat\n",
      "train/cat.10121.jpg is not cat\n",
      "train/cat.10312.jpg is not cat\n",
      "train/cat.10610.jpg is not cat\n",
      "train/cat.10712.jpg is not Dog or Cat\n",
      "train/cat.11184.jpg is not Dog or Cat\n",
      "train/cat.11222.jpg is not cat\n",
      "train/cat.11333.jpg is not cat\n",
      "train/cat.11684.jpg is not cat\n",
      "train/cat.11735.jpg is not cat\n",
      "train/cat.11777.jpg is not Dog or Cat\n",
      "train/cat.1193.jpg is not cat\n",
      "train/cat.1497.jpg is not cat\n",
      "train/cat.1537.jpg is not cat\n",
      "train/cat.2257.jpg is not cat\n",
      "train/cat.2337.jpg is not Dog or Cat\n",
      "train/cat.2384.jpg is not cat\n",
      "train/cat.2588.jpg is not cat\n",
      "train/cat.2817.jpg is not cat\n",
      "train/cat.3087.jpg is not cat\n",
      "train/cat.3181.jpg is not cat\n",
      "train/cat.326.jpg is not cat\n",
      "train/cat.3300.jpg is not cat\n",
      "train/cat.3483.jpg is not cat\n",
      "train/cat.4338.jpg is not Dog or Cat\n",
      "train/cat.4637.jpg is not cat\n",
      "train/cat.5351.jpg is not Dog or Cat\n",
      "train/cat.5418.jpg is not Dog or Cat\n",
      "train/cat.5836.jpg is not cat\n",
      "train/cat.5981.jpg is not cat\n",
      "train/cat.6319.jpg is not cat\n",
      "train/cat.6543.jpg is not cat\n",
      "train/cat.661.jpg is not cat\n",
      "train/cat.7564.jpg is not Dog or Cat\n",
      "train/cat.7599.jpg is not cat\n",
      "train/cat.7661.jpg is not cat\n",
      "train/cat.7968.jpg is not Dog or Cat\n",
      "train/cat.8059.jpg is not cat\n",
      "train/cat.8106.jpg is not cat\n",
      "train/cat.8455.jpg is not cat\n",
      "train/cat.8456.jpg is not Dog or Cat\n",
      "train/cat.8504.jpg is not cat\n",
      "train/cat.8657.jpg is not cat\n",
      "train/cat.8921.jpg is not Dog or Cat\n",
      "train/cat.8990.jpg is not cat\n",
      "train/cat.9171.jpg is not Dog or Cat\n",
      "train/cat.9589.jpg is not cat\n",
      "train/cat.9695.jpg is not cat\n",
      "train/cat.9697.jpg is not cat\n",
      "train/dog.10161.jpg is not Dog or Cat\n",
      "train/dog.10190.jpg is not Dog or Cat\n",
      "train/dog.10237.jpg is not Dog or Cat\n",
      "train/dog.10801.jpg is not Dog or Cat\n",
      "train/dog.12376.jpg is not Dog or Cat\n",
      "train/dog.1773.jpg is not Dog or Cat\n",
      "train/dog.1895.jpg is not Dog or Cat\n",
      "train/dog.2422.jpg is not Dog or Cat\n",
      "train/dog.2614.jpg is not Dog or Cat\n",
      "train/dog.4367.jpg is not Dog or Cat\n",
      "train/dog.5604.jpg is not Dog or Cat\n",
      "train/dog.6475.jpg is not Dog or Cat\n",
      "train/dog.8736.jpg is not Dog or Cat\n"
     ]
    }
   ],
   "source": [
    "find_outliers(inception_v3.InceptionV3, (299,299), inception_v3, \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 160s 102ms/step\n",
      "predicts shape: (25000, 1000)\n",
      "train/cat.10029.jpg is not Dog or Cat\n",
      "train/cat.10107.jpg is not cat\n",
      "train/cat.10121.jpg is not cat\n",
      "train/cat.10712.jpg is not Dog or Cat\n",
      "train/cat.10961.jpg is not cat\n",
      "train/cat.10979.jpg is not cat\n",
      "train/cat.11118.jpg is not cat\n",
      "train/cat.11222.jpg is not cat\n",
      "train/cat.11231.jpg is not cat\n",
      "train/cat.11399.jpg is not cat\n",
      "train/cat.11726.jpg is not cat\n",
      "train/cat.12361.jpg is not cat\n",
      "train/cat.12392.jpg is not cat\n",
      "train/cat.1277.jpg is not cat\n",
      "train/cat.1537.jpg is not cat\n",
      "train/cat.1779.jpg is not cat\n",
      "train/cat.1906.jpg is not cat\n",
      "train/cat.2159.jpg is not cat\n",
      "train/cat.2257.jpg is not cat\n",
      "train/cat.23.jpg is not cat\n",
      "train/cat.2520.jpg is not Dog or Cat\n",
      "train/cat.2568.jpg is not cat\n",
      "train/cat.2817.jpg is not cat\n",
      "train/cat.2893.jpg is not cat\n",
      "train/cat.2939.jpg is not Dog or Cat\n",
      "train/cat.3004.jpg is not Dog or Cat\n",
      "train/cat.3064.jpg is not cat\n",
      "train/cat.326.jpg is not cat\n",
      "train/cat.3300.jpg is not cat\n",
      "train/cat.36.jpg is not cat\n",
      "train/cat.3672.jpg is not Dog or Cat\n",
      "train/cat.3713.jpg is not cat\n",
      "train/cat.3766.jpg is not cat\n",
      "train/cat.4085.jpg is not cat\n",
      "train/cat.4308.jpg is not Dog or Cat\n",
      "train/cat.4338.jpg is not Dog or Cat\n",
      "train/cat.4455.jpg is not cat\n",
      "train/cat.4575.jpg is not cat\n",
      "train/cat.4637.jpg is not cat\n",
      "train/cat.4688.jpg is not Dog or Cat\n",
      "train/cat.4773.jpg is not cat\n",
      "train/cat.4976.jpg is not cat\n",
      "train/cat.5071.jpg is not Dog or Cat\n",
      "train/cat.5241.jpg is not cat\n",
      "train/cat.5351.jpg is not Dog or Cat\n",
      "train/cat.5477.jpg is not cat\n",
      "train/cat.5733.jpg is not cat\n",
      "train/cat.5911.jpg is not cat\n",
      "train/cat.6307.jpg is not cat\n",
      "train/cat.6337.jpg is not cat\n",
      "train/cat.6345.jpg is not Dog or Cat\n",
      "train/cat.6442.jpg is not cat\n",
      "train/cat.6515.jpg is not cat\n",
      "train/cat.7047.jpg is not cat\n",
      "train/cat.7362.jpg is not cat\n",
      "train/cat.7377.jpg is not Dog or Cat\n",
      "train/cat.7464.jpg is not Dog or Cat\n",
      "train/cat.7520.jpg is not cat\n",
      "train/cat.7564.jpg is not Dog or Cat\n",
      "train/cat.7599.jpg is not cat\n",
      "train/cat.7661.jpg is not cat\n",
      "train/cat.7671.jpg is not cat\n",
      "train/cat.7936.jpg is not cat\n",
      "train/cat.7968.jpg is not Dog or Cat\n",
      "train/cat.8122.jpg is not cat\n",
      "train/cat.8198.jpg is not cat\n",
      "train/cat.8289.jpg is not cat\n",
      "train/cat.8456.jpg is not Dog or Cat\n",
      "train/cat.8470.jpg is not Dog or Cat\n",
      "train/cat.8657.jpg is not cat\n",
      "train/cat.8990.jpg is not cat\n",
      "train/cat.9171.jpg is not Dog or Cat\n",
      "train/cat.9444.jpg is not cat\n",
      "train/dog.10161.jpg is not Dog or Cat\n",
      "train/dog.10190.jpg is not Dog or Cat\n",
      "train/dog.10237.jpg is not Dog or Cat\n",
      "train/dog.10747.jpg is not Dog or Cat\n",
      "train/dog.10801.jpg is not Dog or Cat\n",
      "train/dog.11266.jpg is not Dog or Cat\n",
      "train/dog.12376.jpg is not Dog or Cat\n",
      "train/dog.1773.jpg is not Dog or Cat\n",
      "train/dog.1895.jpg is not Dog or Cat\n",
      "train/dog.2422.jpg is not Dog or Cat\n",
      "train/dog.2614.jpg is not Dog or Cat\n",
      "train/dog.4367.jpg is not Dog or Cat\n",
      "train/dog.5604.jpg is not Dog or Cat\n",
      "train/dog.6475.jpg is not Dog or Cat\n",
      "train/dog.8736.jpg is not Dog or Cat\n",
      "train/dog.9188.jpg is not Dog or Cat\n",
      "train/dog.9517.jpg is not Dog or Cat\n"
     ]
    }
   ],
   "source": [
    "find_outliers(inception_resnet_v2.InceptionResNetV2, (299,299), inception_resnet_v2,\"InceptionResNetV2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剔除异常值\n",
    "\n",
    "把'pre-train/'图片复制到'clear-train/', 把outlier list中的文件从'clear-train/'中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog.0.jpg', 'dog.5.jpg']\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ResNet50'\n",
    "def read_outliers_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "filename = 'outlier/' + model_name + \"_outliers.txt\"\n",
    "outlier_files = []\n",
    "outlier_files += read_outliers_from_file(filename)\n",
    "# outlier_files += read_outliers_from_file('outlier/Xception.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/InceptionResNetV2.txt')\n",
    "print(outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def clean_data(old_dir, clean_dir, outlier_list):\n",
    "    if os.path.exists(clean_dir):\n",
    "        shutil.rmtree(clean_dir)\n",
    "    os.mkdir(clean_dir)\n",
    "    \n",
    "    file_list = os.listdir(old_dir)\n",
    "    for filename in file_list:\n",
    "        os.symlink('../../'+old_dir+filename, clean_dir+'/'+filename)\n",
    "    \n",
    "    for filename in outlier_list:\n",
    "        os.remove(clean_dir+'/'+filename)\n",
    "    print('clean over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean over\n"
     ]
    }
   ],
   "source": [
    "clean_data(pending_clean_dir+'/train', cleaned_dir, outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
