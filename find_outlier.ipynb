{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 3:\n",
    "    \n",
    "    raise Exception('请使用Python3来完成此项目')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用在ImageNet上训练过的pre-trained model对训练集进行预测，对比预测结果与真实图片是否一致，如否则属异常值\n",
    "\n",
    "pre-trained model输出的是属于猫和狗的种类的概率，狗有118个品种， 猫有7个品种， 如何判断输出结果是猫还是狗呢？\n",
    "\n",
    "- 如某张图的预测结果的Top-N中，既不是‘dogs',也不是'cats'，则认为此图为异常图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cat_breeds = [\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-trained predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import *\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def predict_image(MODEL, image_size, preprocess_input, decode_predictions, top_n, image_path):\n",
    "    # using the pre-training weights in ImageNet dataset\n",
    "    base_model = MODEL(weights='imagenet')\n",
    "    \n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "        \n",
    "    preds = base_model.predict(x)\n",
    "    \n",
    "    return decode_predictions(preds, top=top_n)[0]\n",
    "#     print('predicted:', decode_predictions(preds, top=3)[0])\n",
    "    \n",
    "def find_outlier(MODEL, image_size, model_class, model_name):\n",
    "    file_list = os.listdir('train/')\n",
    "    top_N = 20\n",
    "    outlier_files = []\n",
    "    for fname in file_list[:1000]:\n",
    "        fpath = os.path.join('train/', fname)\n",
    "        preds = predict_image(MODEL, image_size, \n",
    "                              model_class.preprocess_input, \n",
    "                              model_class.decode_predictions,\n",
    "                             top_n = top_N,\n",
    "                             image_path=fpath)\n",
    "        print(\"decode pred:\",preds)\n",
    "        \n",
    "        outlier_flag = True\n",
    "        for pet in preds:\n",
    "            if pet[0] in dog_breeds or pet[0] in cat_breeds:\n",
    "                outlier_flag = False\n",
    "                break;\n",
    "        \n",
    "        # 检查预测概率最高的品种是否错误\n",
    "        if outlier_flag == False:\n",
    "            pet = preds[0]\n",
    "            if pet[2] > 0.6:\n",
    "                if pet[0] in dog_breeds and fname[:3] == 'cat': # 指猫为'dog'\n",
    "                    outlier_flag = True\n",
    "                    print(\"Cat is not Dog\")\n",
    "                    \n",
    "                if pet[0] in cat_breeds and fname[:3] == 'dog':\n",
    "                    outlier_flag = True\n",
    "                    print(\"Dos is not cat\")\n",
    "                \n",
    "        if outlier_flag:\n",
    "            outlier_files.append(fname)\n",
    "            print('%s is a outlier !' %fname)\n",
    "    \n",
    "    # save the outlier to file\n",
    "    out_filename = 'outlier/' + model_name + \".txt\"\n",
    "    with open(out_filename,'w') as f:\n",
    "        f.write(str(outlier_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode pred: [('n02124075', 'Egyptian_cat', 0.56555563), ('n02123045', 'tabby', 0.28696027), ('n02127052', 'lynx', 0.051270023), ('n02123159', 'tiger_cat', 0.035105415), ('n04209239', 'shower_curtain', 0.012346651), ('n02808440', 'bathtub', 0.0040852465), ('n02971356', 'carton', 0.0040702336), ('n04589890', 'window_screen', 0.003119407), ('n03958227', 'plastic_bag', 0.0023623363), ('n04493381', 'tub', 0.0022657104), ('n02808304', 'bath_towel', 0.0019139963), ('n02325366', 'wood_rabbit', 0.0017331188), ('n02114855', 'coyote', 0.0016469031), ('n02326432', 'hare', 0.0014933287), ('n04553703', 'washbasin', 0.0013880422), ('n02120505', 'grey_fox', 0.0011291141), ('n02909870', 'bucket', 0.0010200642), ('n04070727', 'refrigerator', 0.0009789072), ('n03223299', 'doormat', 0.00089990476), ('n03443371', 'goblet', 0.00082443375)]\n",
      "decode pred: [('n02123045', 'tabby', 0.73149043), ('n02123159', 'tiger_cat', 0.19419812), ('n02124075', 'Egyptian_cat', 0.019166976), ('n02127052', 'lynx', 0.019048095), ('n02123394', 'Persian_cat', 0.010066337), ('n02129604', 'tiger', 0.0020342772), ('n02128385', 'leopard', 0.00096953596), ('n03958227', 'plastic_bag', 0.00085133844), ('n04367480', 'swab', 0.00084386586), ('n03325584', 'feather_boa', 0.0005885958), ('n03598930', 'jigsaw_puzzle', 0.00044283835), ('n03085013', 'computer_keyboard', 0.00041691688), ('n02939185', 'caldron', 0.00038434236), ('n02971356', 'carton', 0.0003781957), ('n04589890', 'window_screen', 0.00032785), ('n02128757', 'snow_leopard', 0.0002908884), ('n03942813', 'ping-pong_ball', 0.00028583832), ('n13133613', 'ear', 0.00027895486), ('n04074963', 'remote_control', 0.00027642434), ('n03223299', 'doormat', 0.00027587154)]\n",
      "is cat not dog\n",
      "cat.898.jpg is a outlier !\n"
     ]
    }
   ],
   "source": [
    "find_outlier(resnet50.ResNet50, (224,224), resnet50, \"ResNet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "1563/1563 [==============================] - 98s 63ms/step\n",
      "782/782 [==============================] - 49s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "find_outlier(xception.Xception, (299,299), xception.preprocess_input, \"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outlier(inception_resnet_v2.InceptionResNetV2, (299,299), inception_resnet_v2.preprocess_input,\"InceptionResNetV2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剔除异常值\n",
    "\n",
    "把'train/'图片复制到'clear-train/', 把outlier list中的文件从'clear-train/'中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.898.jpg']\n"
     ]
    }
   ],
   "source": [
    "def read_outliers_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    obj = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return obj\n",
    "\n",
    "outlier_files = []\n",
    "outlier_files += read_outliers_from_file('outlier/ResNet50.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/Xception.txt')\n",
    "# outlier_files += read_outliers_from_file('outlier/InceptionResNetV2.txt')\n",
    "print(outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def clean_data(old_dir, clean_dir, outlier_list):\n",
    "    if os.path.exists(clean_dir):\n",
    "        shutil.rmtree(clean_dir)\n",
    "    os.mkdir(clean_dir)\n",
    "    \n",
    "    file_list = os.listdir(old_dir)\n",
    "    for filename in file_list:\n",
    "        if filename not in outlier_list:\n",
    "            os.symlink('../'+old_dir+filename, clean_dir+filename)\n",
    "    \n",
    "    print('clean over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean over\n"
     ]
    }
   ],
   "source": [
    "clean_data('train/', 'clean-train/', outlier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
