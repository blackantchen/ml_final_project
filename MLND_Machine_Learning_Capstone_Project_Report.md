# 机器学习纳米学位毕业项目

## 猫狗大战 (Dogs vs. Cats)



Chen Yifan

July 30th, 2018



<div style="page-break-after:always;"></div>


[TOC]

<div style="page-break-after:always;"></div>


## 1 定义
### 1.1 项目概述

​         <Dogs vs. Cats Redux:Kernel Edition> 是kaggle的一个竞赛项目，目标是建立一个模型，将给定的图片分辨为猫或狗。这是一个图像分类问题，是典型的计算机视觉问题。

​        图像分类是计算机视觉研究中的经典问题，基于图像分类的研究成果和方法广泛应用在诸如目标检测已经图像摘要生成等领域。从 2010 年开始举办的 ImageNet 大规模视觉识别挑战赛[^1] (ILSVRC)代表了这些领域的世界先进水平。2012年，以卷积神经网络[^2] (Convolutional Neural Network, CNN)为代表的深度学习方法开始在挑战赛中独领风骚；此后几年，基于CNN的神经网络模型不断有新的研究成果出现，并且连续几年获得挑战赛冠军，可见CNN在计算机视觉领域的巨大优势。

​        作为一个典型的图像分类问题，本项目计划使用CNN网络来构建模型，考虑到训练CNN网络需要用到巨大的计算资源，拟采用Keras的Applications模块提供了带有预训练权重的深度学习模型以减少对计算资源的要求. Keras是一个高层神经网络API，Keras由纯Python编写而成并基[Tensorflow](https://github.com/tensorflow/tensorflow)、[Theano](https://github.com/Theano/Theano)以及[CNTK](https://github.com/Microsoft/cntk)后端。Keras提供的应用于图像分类的预训练模型，其权重训练自ImageNet。

​         本项目采用Kaggle竞赛项目《Dogs vs. Cats Redux: Kernels 》的数据集，图片分为train和test两个数据集； train中共有25000张图片，其中猫和狗各有12500张 ，test中包含12500张未标注的图片. 对于test中的每一张图片，模型需要预测出图像是狗的概率(1.0 代表狗，0 代表猫).



### 1.2 问题陈述

​        Kaggle竞赛提供的数据是从真实世界采集的猫和狗的图片，图像分辨率差异较大，质量参差不齐，图片中猫和狗品质多样，颜色和姿态各异，背景多变，这些都增加了图像分类的难度。

​        项目的目标是建立一个模型，将给定的图片分辨为猫或狗，这是典型的图像二分类问题; 通过训练集中大量已经标注为猫或狗的图片对模型进行训练，用训练好的模型预测未知的图片，模型的输出为图片是狗的概率，概率为1.0表示狗，0表示猫 。



### 1.3 评价指标



本次猫狗大战(Dogs vs. Cats Redux: Kernels Edition)中使用logloss[2]作为评价指标, 分数计算如下:
$$
LogLoss = -\frac{1}{n} \sum_{i=1}^{n}{[y_i log(\hat{y_i})+(1-y_i)log(1-\hat{y_i})]}
$$

其中：

- n是图片的数量

- $\hat{y_i}$是模型预测为狗的概率

- $y_i$ 是类别标签，1对应狗，0对应猫

- log 是自然对数

LogLoss是一个连续值, 取值范围 是0至无穷大, 相比Accuracy, LogLoss能对模型提供更细致的评价. 在深度学习成为主流的今天, 模型对图像分类的准确率都非常高, 模型之间的性能差异较小, 使用LogLoss作为评价指标能以更细微的视角观察到模型性能之间差异

## 2 分析
### 2.1 数据探索

​         项目的训练集和测试集全部来自于Kaggle竞赛项目《Dogs vs. Cats Redux: Kernels 》 ，图片分为train和test两个数据集 ，绝大部分都是各种猫和狗的图片；train中共有25000张图片，其中猫和狗各有12500张；所有图片都已经在文件名中标注为猫或狗，如cat.xxx.jpg, dog.xxx.jpg, 由于猫狗比例相等，因此模型不需要考虑类别不平衡问题。

测试集中包含12500张未标注的图片, 图片内容都是各种猫和狗.

### 2.2 探索可视化

​        随机选取部分图片进行观察，图片基本都是RGB的彩色图片，包含不同品种的猫和狗，姿态，背景各异；其中有猫狗单独的照片，有人类牵引，拥抱的合照， 也有猫和狗的合照；大部分图片分辨率和质量较好，个别图片分辨率和质量较差。

- 训练样本展示

- 分辨率分布图

  

### 2.3 算法和技术

#### 2.3.1 深度学习
​        深度学习作为机器学习算法研究中的一个新的技术，其动机在于建立、模拟人脑进行分析学习的神经网络。深度学习是相对于简单学习而言的，目前多数分类、回归等学习算法都属于简单学习或者浅层结构，浅层结构通常只包含1层或2层的非线性特征转换层，典型的浅层结构有高斯混合模型(GMM)、隐马尔科夫模型(HMM)、条件随机域(CRF)、最大熵模型(MEM)、逻辑回归(LR)、支持向量机(SVM)和多层感知器(MLP)。浅层结构学习模型的相同点是采用一层简单结构将原始输入信号或特征转换到特定问题的特征空间中。浅层模型的局限性对复杂函数的表示能力有限，针对复杂分类问题其泛化能力受到一定的制约，比较难解决一些更加复杂的自然信号处理问题，例如人类语音和自然图像等。而深度学习可通过学习一种深层非线性网络结构，表征输入数据，实现复杂函数逼近，并展现了强大的从少数样本集中学习数据集本质特征的能力。
       深度学习通过学习一种深层非线性网络结构，只需简单的网络结构即可实现复杂函数的逼近，并展现了强大的从大量无标注样本集中学习数据集本质特征的能力。深度学习能够获得可更好地表示数据的特征，同时由于模型的层次深、表达能力强，因此有能力表示大规模数据。对于图像、语音这种特征不明显（需要手工设计且很多没有直观的物理含义）的问题，深度模型能够在大规模训练数据上取得更好的效果。相比于传统的神经网络，深度神经网络作出了重大的改进，在训练上的难度（如梯度弥散问题）可以通过“逐层预训练”来有效降低。

#### 2.3.2 卷积神经网络

​        卷积神经网络（Convolutional Neural Network, CNN）是一种前馈人工神经网络，一般情况下，卷积神经网络由一个或者多个卷积层，池化层，激活函数以及顶端全连接层组成。与其他深度学习结构相比，卷积神经网络在图像和[语音识别](https://zh.wikipedia.org/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB)方面能够给出更好的结果 ; 相比较其他深度、前馈神经网络，卷积神经网络需要考量的参数更少，使之成为一种颇具吸引力的深度学习结构.

- 卷积层(Convolutional Layer): 卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过[反向传播算法](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95)最佳化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网路能从低级特征中迭代提取更复杂的特征 .
- 池化层(Pooling Layer): 池化（Pooling）是卷积神经网络中另一个重要的概念，它实际上是一种形式的下采样。池化层有多种形式的池化函数, 如 “最大池化（Max pooling）”, "平均池化(Average Pooling)"等。以最大池化为例, 它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效地原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了[过拟合](https://zh.wikipedia.org/wiki/%E8%BF%87%E6%8B%9F%E5%90%88)。通常来说，CNN的卷积层之间都会周期性地插入池化层。 
- 全连接层(Fully Connected Layer): 是一个传统的多层感知器, “全连接”表示上一层的每一个神经元，都和下一层的每一个神经元是相互连接的。 卷积层和池化层的输出代表了输入的高级特征。完全连接层的目的是利用这些基于训练数据集得到的特征，将输入分为不同的类.



#### 2.3.3 技术实现

​         项目使用深度学习库 Tensorflow 和 基于 Tensorflow 的高层神经网络API Keras 进行开发。

​         Tensorflow 是由Google 开发的开源机器学习库。最初由Google Brain小组开发，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域.

​        Tensorflow 它是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。数据流图用“结点”（nodes）和“线”(edges)的有向图来描述数学计算。“节点” 一般用来表示施加的数学操作，但也可以表示数据输入（feed in）的起点/输出（push out）的终点，或者是读取/写入持久变量（persistent variable）的终点。“线”表示“节点”之间的输入/输出关系。这些数据“线”可以输运“size可动态调整”的多维数据数组，即“张量”（tensor）。 理论上，只要能将计算表示为一个数据流图，就可以使用Tensorflow,  因此卷积神经网络也可以由 Tensorflow 来搭建.

​        Keras是一个高层神经网络API，可以基于Tensorflow、Theano以及CNTK作为后端。Keras支持CNN和RNN, 或二者的结合, 提供了高度模块化和易于使用的API, 可以非常方便和快速的进行模型设计. 此外, Keras的Application模块提供了带有预训练权重的Kears模型, 如ResNet50, Xception, InceptionV3等, 这些模型可以用来进行预测,特征提取和finetune, 应用这些预训练模型可以极大的简化模型设计.

​        使用CNN处理高分辨率彩色图像所需的计算量非常大, 项目使用GPU进行计算加速. 对于没有GPU资源的个人用户,  可以选择 Amazon 提供的云计算服务 EC2 (Elastic Compute Cloud), 综合考虑性价比, 最终选择p3.2xlarge实例作为项目的运行平台, 该实例配备1个NVIDIA Tesla V100 高性能GPU, Intel Xeon E5-2686 v4 处理器, 61GB内存, 以及16GB现存.



### 2.4 基准模型
​         最近几年，在ImageNet挑战赛中涌现了许多优秀的卷积神经网络模型，如ResNet50, Xception, InceptionV3, InceptionResNetV2等。这些模型对ImageNet数据集上的1000个类别进行分类，最好的Top-5准确率高达0.92以上。
        本次竞赛仅对猫狗进行分类，若想准确率到达0.92以上，则对数损失必须控制在0.1以内；kaggle排名前10%的成绩达到了0.06114, 排名100的成绩是0.05629，项目设定的目标是LogLoss分数小于0.056, 即进入排名100以内、
## 3 方法
### 3.1 模型选择

​         如表-1所示, 在 ImageNet[^3] 竞赛中取得优异成绩的CNN模型, 其深度常常超过100层, 从零开始训练一个类似的模型, 并让模型习得优异的性能, 不仅需要大量计算资源, 同时也需要巨量的训练样本来训练模型;  使用 Keras 提供的带有预训练权重的模型来构建迁移学习模型, 既能大幅减少对计算资源的要求, 提供训练效率, 同时也能减少因项目训练集不够而引起模型"过拟合"的风险.

​       Keras 提供的应用于图像分类的预训练模型，其权重训练自ImageNet. ImageNet是目前

​         


表-1
| 模型             | 大小  | Top1准确率 | Top5准确率 | 参数数目    | 深度 |
| ---------------- | ----- | ---------- | ---------- | ----------- | ---- |
| Xception         | 88MB  | 0.790      | 0.945      | 22,910,480  | 126  |
| VGG16            | 528MB | 0.715      | 0.901      | 138,357,544 | 23   |
| VGG19            | 549MB | 0.727      | 0.910      | 143,667,240 | 26   |
| ResNet50         | 99MB  | 0.759      | 0.929      | 25,636,712  | 168  |
| InceptionV3      | 92MB  | 0.788      | 0.944      | 23,851,784  | 159  |
| IncetionResNetV2 | 215MB | 0.804      | 0.953      | 55,873,736  | 572  |
| MobileNet        | 17MB  | 0.665      | 0.871      | 4,253,864   | 88   |

### 3.2 数据预处理

### 3.3 执行过程
### 3.4 完善

## 4 结果
### 4.1 模型的评价与验证
### 4.2 结果分析

## 5 项目结论
### 5.1 结果可视化
### 5.2 改进

## 参考文献
[^1]: Large Scale Visual Recognition Challenge 2016
[^2]: 