# 机器学习纳米学位毕业项目
## 猫狗大战 (Dogs vs. Cats)

---
Chen Yifan

July 30th, 2018

---

[TOC]

---

## 1 定义
### 1.1 项目概述

​         <Dogs vs. Cats Redux:Kernel Edition> 是kaggle的一个竞赛项目，目标是建立一个模型，将给定的图片分辨为猫或狗。这是一个图像分类问题，是典型的计算机视觉问题。

​        图像分类是计算机视觉研究中的经典问题，基于图像分类的研究成果和方法广泛应用在诸如目标检测已经图像摘要生成等领域。从 2010 年开始举办的 ImageNet 大规模视觉识别挑战赛[^1] (ILSVRC)代表了这些领域的世界先进水平。2012年，以卷积神经网络[^2] (Convolutional Neural Network, CNN)为代表的深度学习方法开始在挑战赛中独领风骚；此后几年，基于CNN的神经网络模型不断有新的研究成果出现，并且连续几年获得挑战赛冠军，可见CNN在计算机视觉领域的巨大优势。

​        作为一个典型的图像分类问题，本项目计划使用CNN网络来构建模型，考虑到训练CNN网络需要用到巨大的计算资源，拟采用Keras的Applications模块提供了带有预训练权重的深度学习模型以减少对计算资源的要求. Keras是一个高层神经网络API，Keras由纯Python编写而成并基[Tensorflow](https://github.com/tensorflow/tensorflow)、[Theano](https://github.com/Theano/Theano)以及[CNTK](https://github.com/Microsoft/cntk)后端。Keras提供的应用于图像分类的预训练模型，其权重训练自ImageNet。

​         本项目采用Kaggle竞赛项目《Dogs vs. Cats Redux: Kernels 》的数据集，图片分为train和test两个数据集； train中共有25000张图片，其中猫和狗各有12500张 ，test中包含12500张未标注的图片. 对于test中的每一张图片，模型需要预测出图像是狗的概率(1.0 代表狗，0 代表猫).



### 1.2 问题陈述

​        Kaggle竞赛提供的数据是从真实世界采集的猫和狗的图片，图像分辨率差异较大，质量参差不齐，图片中猫和狗品质多样，颜色和姿态各异，背景多变，这些都增加了图像分类的难度。

​        项目的目标是建立一个模型，将给定的图片分辨为猫或狗，这是典型的图像二分类问题; 通过训练集中大量已经标注为猫或狗的图片对模型进行训练，用训练好的模型预测未知的图片，模型的输出为图片是狗的概率，概率为1.0表示狗，0表示猫 。



### 1.3 评价指标



本次猫狗大战(Dogs vs. Cats Redux: Kernels Edition)中使用logloss[2]作为评价指标, 分数计算如下:
$$
LogLoss = -\frac{1}{n} \sum_{i=1}^{n}{[y_i log(\hat{y_i})+(1-y_i)log(1-\hat{y_i})]}
$$

其中：

- n是图片的数量

- $\hat{y_i}$是模型预测为狗的概率

- $y_i$ 是类别标签，1对应狗，0对应猫

- log 是自然对数

LogLoss是一个连续值, 取值范围 是0至无穷大, 相比Accuracy, LogLoss能对模型提供更细致的评价. 在深度学习成为主流的今天, 模型对图像分类的准确率都非常高, 模型之间的性能差异较小, 使用LogLoss作为评价指标能以更细微的视角观察到模型性能之间差异

## 2 分析
### 2.1 数据探索

​         项目的训练集和测试集全部来自于Kaggle竞赛项目《Dogs vs. Cats Redux: Kernels 》 ，图片分为train和test两个数据集 ，绝大部分都是各种猫和狗的图片；train中共有25000张图片，其中猫和狗各有12500张；所有图片都已经在文件名中标注为猫或狗，如cat.xxx.jpg, dog.xxx.jpg, 由于猫狗比例相等，因此模型不需要考虑类别不平衡问题。

测试集中包含12500张未标注的图片, 图片内容都是各种猫和狗.

### 2.2 探索可视化

​        随机选取部分图片进行观察，图片基本都是RGB的彩色图片，包含不同品种的猫和狗，姿态，背景各异；其中有猫狗单独的照片，有人类牵引，拥抱的合照， 也有猫和狗的合照；大部分图片分辨率和质量较好，个别图片分辨率和质量较差。

- 训练样本展示

- 分辨率分布图

  

### 2.3 算法和技术

#### 2.3.1 深度学习
​        深度学习作为机器学习算法研究中的一个新的技术，其动机在于建立、模拟人脑进行分析学习的神经网络。深度学习是相对于简单学习而言的，目前多数分类、回归等学习算法都属于简单学习或者浅层结构，浅层结构通常只包含1层或2层的非线性特征转换层，典型的浅层结构有高斯混合模型(GMM)、隐马尔科夫模型(HMM)、条件随机域(CRF)、最大熵模型(MEM)、逻辑回归(LR)、支持向量机(SVM)和多层感知器(MLP)。浅层结构学习模型的相同点是采用一层简单结构将原始输入信号或特征转换到特定问题的特征空间中。浅层模型的局限性对复杂函数的表示能力有限，针对复杂分类问题其泛化能力受到一定的制约，比较难解决一些更加复杂的自然信号处理问题，例如人类语音和自然图像等。而深度学习可通过学习一种深层非线性网络结构，表征输入数据，实现复杂函数逼近，并展现了强大的从少数样本集中学习数据集本质特征的能力。
       深度学习通过学习一种深层非线性网络结构，只需简单的网络结构即可实现复杂函数的逼近，并展现了强大的从大量无标注样本集中学习数据集本质特征的能力。深度学习能够获得可更好地表示数据的特征，同时由于模型的层次深、表达能力强，因此有能力表示大规模数据。对于图像、语音这种特征不明显（需要手工设计且很多没有直观的物理含义）的问题，深度模型能够在大规模训练数据上取得更好的效果。相比于传统的神经网络，深度神经网络作出了重大的改进，在训练上的难度（如梯度弥散问题）可以通过“逐层预训练”来有效降低。

#### 2.3.2 卷积神经网络



#### 2.3.3 技术实现

​         项目使用深度学习库 Tensorflow 和 基于 Tensorflow 的高层神经网络API Keras 进行开发。

​         Tensorflow 是由Google 开发的开源机器学习库。最初由Google Brain小组开发，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域.

​        Tensorflow 它是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。数据流图用“结点”（nodes）和“线”(edges)的有向图来描述数学计算。“节点” 一般用来表示施加的数学操作，但也可以表示数据输入（feed in）的起点/输出（push out）的终点，或者是读取/写入持久变量（persistent variable）的终点。“线”表示“节点”之间的输入/输出关系。这些数据“线”可以输运“size可动态调整”的多维数据数组，即“张量”（tensor）。 理论上，只要能将计算表示为一个数据流图，就可以使用Tensorflow,  因此卷积神经网络也可以由 Tensorflow 来搭建.



### 2.4 基准模型
​         最近几年，在ImageNet挑战赛中涌现了许多优秀的卷积神经网络模型，如ResNet50, Xception, InceptionV3, InceptionResNetV2等。这些模型对ImageNet数据集上的1000个类别进行分类，最好的Top-5准确率高达0.92以上。
        本次竞赛仅对猫狗进行分类，若想准确率到达0.92以上，则对数损失必须控制在0.1以内；kaggle排名前10%的成绩达到了0.06114, 排名100的成绩是0.05629，项目设定的目标是LogLoss分数小于0.056, 即进入排名100以内、
## 3 方法
### 3.1 数据预处理
### 3.2 执行过程
### 3.3 完善

## 4 结果
### 4.1 模型的评价与验证
### 4.2 结果分析

## 5 项目结论
### 5.1 结果可视化
### 5.2 改进

## 参考文献
[^1]: Large Scale Visual Recognition Challenge 2016
[^2]: 