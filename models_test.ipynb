{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 3:\n",
    "    raise Exception('请使用Python3来完成此项目')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据\n",
    "[Dogs vs. Cats Redux: Kernels Edition\n",
    "](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is exist, no need download\n",
      "files found\n",
      "file is exist, no need download\n",
      "files found\n"
     ]
    }
   ],
   "source": [
    "# download data and unzip it\n",
    "# from urllib.request import urlretrieve\n",
    "import subprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "train_url = ['kaggle','competitions','download','-c','dogs-vs-cats-redux-kernels-edition',\n",
    "            '-f','train.zip','-p','./']\n",
    "test_url = ['kaggle','competitions','download','-c','dogs-vs-cats-redux-kernels-edition',\n",
    "            '-f','test.zip','-p','./']\n",
    "sample_csv_url = ['kaggle','competitions','download','-c','dogs-vs-cats-redux-kernels-edition',\n",
    "                  '-f','sample_submission.csv','-p','./']\n",
    "\n",
    "\n",
    "def download_unzip_dataset(url, zip_file_path, folder_path, unzip=True):\n",
    "    if os.path.exists(zip_file_path):\n",
    "        print(\"file is exist, no need download\")\n",
    "    else:\n",
    "        print(\"download now\")\n",
    "#         urlretrieve(url, zip_file_path)\n",
    "        subp = subprocess.run(url)\n",
    "#         subp.wait()\n",
    "    \n",
    "    if unzip:\n",
    "        if os.path.exists(folder_path):\n",
    "            print(\"files found\")\n",
    "        else:\n",
    "            print(\"unzip now\")\n",
    "            zipf = ZipFile(zip_file_path)\n",
    "            zipf.extractall()\n",
    "            print(\"unzip end\")\n",
    "\n",
    "download_unzip_dataset(train_url, 'train.zip', 'train/')\n",
    "download_unzip_dataset(test_url, 'test.zip', 'test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分离数据集，dog和cat图片分别放入train2/dogs, train2/cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split over\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_train_set(old_dir, new_dir):\n",
    "    file_list = os.listdir(old_dir)\n",
    "    file_cats = filter(lambda x:x[:3] == 'cat', file_list)\n",
    "    file_dogs = filter(lambda x:x[:3] == 'dog', file_list)\n",
    "\n",
    "    if os.path.exists(new_dir):\n",
    "        shutil.rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "    dogs_path = os.path.join(new_dir, 'dogs')\n",
    "    cats_path = os.path.join(new_dir, 'cats')\n",
    "    os.mkdir(dogs_path)\n",
    "    os.mkdir(cats_path)\n",
    "    \n",
    "    # 此处要注意： os.symlink(src, dst)\n",
    "    # dst是从它所在的目录去选择src,所以src必须是相对于dst的relative path\n",
    "    for filename in file_cats:\n",
    "        os.symlink('../../'+old_dir+filename, cats_path+'/'+filename)\n",
    "    \n",
    "    for filename in file_dogs:\n",
    "        os.symlink(old_dir+filename, dogs_path+'/'+filename)\n",
    "        \n",
    "    print(\"split over\")\n",
    "\n",
    "split_train_set('train/', 'train2/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model in single picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了复用代码，同时也保证测试的一致性，将model的预测试封装为一个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ee190cf55a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# from keras.applications.resnet50 import preprocess_input, decode_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def trained_model_test(MODEL, image_size, preprocess_input, decode_predictions):\n",
    "#     input_tensor = Input((image_size[0], image_size[1], 3)) # shape: width, height, channel\n",
    "    \n",
    "#     if preprocess_input:\n",
    "#         x = preprocess(input_tensor)\n",
    "#     else:\n",
    "#         x = input_tensor\n",
    "        \n",
    "    # using the pre-training weights in ImageNet dataset\n",
    "    base_model = MODEL(weights='imagenet')\n",
    "    \n",
    "    img = image.load_img('test/43.jpg', target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    preds = base_model.predict(x)\n",
    "    print('preds:', preds)\n",
    "    print('predicted:', decode_predictions(preds, top=3)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [('n02106550', 'Rottweiler', 0.9468535), ('n02089078', 'black-and-tan_coonhound', 0.024193374), ('n02107142', 'Doberman', 0.015099439)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import resnet50\n",
    "\n",
    "trained_model_test(resnet50.ResNet50, (224,224), resnet50.preprocess_input, resnet50.decode_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [('n02106550', 'Rottweiler', 0.9479482), ('n02105412', 'kelpie', 0.0116197495), ('n02107142', 'Doberman', 0.006018338)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import xception\n",
    "\n",
    "trained_model_test(xception.Xception, (299,299), xception.preprocess_input, xception.decode_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [('n02106550', 'Rottweiler', 0.90469307), ('n02089078', 'black-and-tan_coonhound', 0.02317639), ('n02105412', 'kelpie', 0.010496103)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "\n",
    "trained_model_test(inception_v3.InceptionV3, (299,299), inception_v3.preprocess_input, inception_v3.decode_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test mode in all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于样本数非常多的数据集，可以利用generator函数来减少计算的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a45ed34f295d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## build model: xception + Dropout + Dense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "## build model: xception + Dropout + Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications import xception\n",
    "\n",
    "# create the base pre-trained model\n",
    "x = Input((299,299,3))\n",
    "base_model = xception.Xception(input_tensor=xception.preprocess_input(x).p, weights='imagenet', include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# add a global spatial average pooling layer, use base_model'output as input\n",
    "x1 = base_model.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "x1 = Dropout(0.25)(x1)\n",
    "\n",
    "# add a fully-connected layer\n",
    "xout = Dense(1, activation='sigmoid')(x1)\n",
    "\n",
    "# this is the model will be train\n",
    "model = Model(inputs=base_model.input, outputs = xout)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-edc5dd58eef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# plot_model(model, to_file='model.png', show_shapes='True')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# plot_model(model, to_file='model.png', show_shapes='True')\n",
    "SVG(model_to_dot(model).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import *\n",
    "\n",
    "image_size = (224,224)\n",
    "\n",
    "image_gen = ImageDataGenerator()\n",
    "train_generator = image_gen.flow_from_directory('train2', \n",
    "                                                target_size=image_size, \n",
    "                                                shuffle=False, \n",
    "                                                batch_size=16)\n",
    "test_generator = image_gen.flow_from_directory('test', \n",
    "                                               target_size=image_size, \n",
    "                                               shuffle=False, \n",
    "                                               batch_size=16, \n",
    "                                               class_mode=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测分类\n",
    "pre-trained模型已经训练过，所以不再需要fit， 除非又加入了新的layer构成了新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "train_preds = model.predict_generator(train_generator)\n",
    "\n",
    "# caculater accuracy\n",
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
