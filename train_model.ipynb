{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use Xception model\n",
      "model name: Xception\n"
     ]
    }
   ],
   "source": [
    "#pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', 'Xception':'Xception_pre_out.h5', 'InceptionV3':'InceptionV3_pre_out.h5'}\n",
    "pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', \n",
    "                      'Xception':'Xception_pre_out.h5', \n",
    "                      'InceptionResNetV2':'InceptionResNetV2_pre_out.h5'}\n",
    "\n",
    "composite_model = False\n",
    "single_model = 'Xception'\n",
    "\n",
    "# check training parameter\n",
    "if not composite_model and single_model not in pre_features_files:\n",
    "    print(\"%s not found in pre-trained models\" %single_model)\n",
    "else:\n",
    "    if composite_model:\n",
    "        print(\"will use composite model\")\n",
    "    else:\n",
    "        print(\"will use %s model\" %single_model)\n",
    "        \n",
    "if composite_model:\n",
    "    model_name = 'Composite_Model'\n",
    "else:\n",
    "    model_name = single_model\n",
    "    \n",
    "print('model name:', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def show_history(hist, title_name):\n",
    "    # epoch as x-axis \n",
    "    epochs = range(len(hist['acc']))\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ## left scale: acc, val_acc\n",
    "    # acc\n",
    "    line_acc = ax1.plot(epochs, hist['acc'], 'r', label='acc')\n",
    "    # loss\n",
    "#     ax1.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    # val_acc\n",
    "    line_val_acc = ax1.plot(epochs, hist['val_acc'], 'b', label='val_acc')\n",
    "    # val_loss\n",
    "#     ax1.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    \n",
    "    ax1.set(xlabel='epochs', ylabel='acc',title=title_name)\n",
    "    \n",
    "    ## right scale: loss, val_loss\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('loss', color=color)  # we already handled the x-label with ax1\n",
    "    line_loss = ax2.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    line_val_loss = ax2.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#     ax1.legend(loc='upper right', fancybox=True,)\n",
    "#     ax2.legend(loc='lower right', fancybox=True)\n",
    "    \n",
    "    ax1.grid(True)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    acc_patch = mpatches.Patch(color='r', label='acc',linestyle='-')\n",
    "    val_acc_patch = mpatches.Patch(color='b', label='val-acc')\n",
    "    loss_patch = mpatches.Patch(color='g', label='loss')\n",
    "    val_loss_patch = mpatches.Patch(color='k', label='val-loss')\n",
    "    fig.legend(handles=[acc_patch, val_acc_patch, loss_patch, val_loss_patch],\n",
    "               ncol=4, loc='lower center',\n",
    "               mode=\"expand\", borderaxespad=0.,)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 2048)\n",
      "train_data: [[0.06419943 0.5325118  0.61818767 ... 0.02308517 0.         0.23087822]\n",
      " [0.01955884 0.2614151  0.00553378 ... 0.         0.02877969 0.04635844]\n",
      " [0.0658308  0.13139124 0.12781699 ... 0.02613068 0.47964153 0.61643195]\n",
      " [0.25487077 0.24022049 0.15445104 ... 0.         0.02235488 0.55988157]\n",
      " [0.03490764 0.2764068  0.12088037 ... 0.08623303 0.14639798 0.60639906]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(66)\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# #------- single pre-trained model\n",
    "if not composite_model:\n",
    "    with h5py.File(pre_features_files[single_model] , 'r') as h:\n",
    "        train_data.append(np.array(h['train']))\n",
    "        train_labels = np.array(h['label'])\n",
    "        test_data.append(np.array(h['test']))\n",
    "else:#-------- composite model\n",
    "    for modelname in pre_features_files:\n",
    "        with h5py.File(pre_features_files[modelname]) as h:\n",
    "            train_data.append(np.array(h['train']))\n",
    "            train_labels = np.array(h['label'])\n",
    "            test_data.append(np.array(h['test']))\n",
    "\n",
    "train_data = np.concatenate(train_data, axis=1)\n",
    "test_data = np.concatenate(test_data, axis=1)\n",
    "\n",
    "print(\"train shape:\",train_data.shape)\n",
    "print(\"train_data:\",train_data[:5])\n",
    "# 预存的X_train, y_train是按顺序存放的，前12500是猫，后12500是狗, 这里打乱顺序，使之随机存放\n",
    "# Note: 打乱的是存放存放顺序，并不改变 X_train , y_train的对应关系\n",
    "train_data, train_labels = shuffle(train_data, train_labels)\n",
    "\n",
    "train_data_unclean = train_data\n",
    "train_labels_unclean = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剔除train中的异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "## outliers list\n",
    "train_outliers=['cat.10636.jpg', 'dog.10161.jpg', 'dog.2614.jpg', 'cat.7564.jpg', 'cat.7377.jpg', 'cat.3216.jpg', 'dog.2422.jpg', 'dog.11266.jpg', 'cat.5071.jpg', 'cat.6345.jpg', 'dog.1773.jpg', 'cat.8456.jpg', 'dog.10190.jpg', 'cat.8921.jpg', 'cat.10029.jpg', 'cat.3004.jpg', 'cat.9171.jpg', 'dog.4218.jpg', 'cat.5418.jpg', 'cat.5974.jpg', 'dog.1895.jpg', 'cat.2520.jpg', 'cat.9983.jpg', 'dog.4507.jpg', 'cat.4338.jpg', 'dog.9188.jpg', 'dog.9517.jpg', 'cat.4308.jpg', 'dog.6475.jpg', 'cat.10365.jpg', 'dog.10237.jpg', 'cat.8470.jpg', 'dog.1625.jpg', 'dog.4367.jpg', 'dog.11299.jpg', 'cat.10536.jpg', 'cat.5351.jpg', 'dog.5604.jpg', 'dog.10747.jpg', 'cat.7464.jpg', 'dog.1259.jpg', 'cat.4688.jpg', 'cat.12272.jpg', 'dog.3889.jpg', 'dog.8898.jpg', 'dog.7706.jpg', 'cat.10712.jpg', 'cat.11184.jpg', 'cat.12476.jpg', 'cat.7968.jpg', 'dog.8736.jpg', 'dog.6725.jpg', 'cat.1139.jpg', 'cat.6348.jpg', 'dog.12376.jpg', 'dog.2339.jpg', 'dog.11437.jpg', 'dog.10801.jpg', 'cat.12424.jpg', 'dog.1194.jpg', 'dog.7076.jpg', 'cat.11039.jpg', 'cat.3672.jpg', 'cat.2939.jpg']\n",
    "\n",
    "train_outliers.remove('cat.1139.jpg')\n",
    "train_outliers.remove('cat.3004.jpg')\n",
    "train_outliers.remove('dog.7706.jpg')\n",
    "\n",
    "print(len(train_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## create train_generator\n",
    "# import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(\"pre-train\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939, 2048)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outliers_index = [i for i,fn in enumerate(train_generator.filenames) if fn.split('/')[1] in train_outliers]\n",
    "train_data = np.array([x for i,x in enumerate(train_data_unclean) if i not in outliers_index])\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.array([x for i,x in enumerate(train_labels_unclean) if i not in outliers_index])\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(666)\n",
    "\n",
    "input_tensor = Input(train_data.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在pre-train features上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19951 samples, validate on 4988 samples\n",
      "Epoch 1/50\n",
      "19951/19951 [==============================] - 3s 129us/step - loss: 0.1421 - acc: 0.9754 - val_loss: 0.0512 - val_acc: 0.9900\n",
      "Epoch 2/50\n",
      "19951/19951 [==============================] - 2s 122us/step - loss: 0.0375 - acc: 0.9919 - val_loss: 0.0319 - val_acc: 0.9916\n",
      "Epoch 3/50\n",
      "19951/19951 [==============================] - 2s 116us/step - loss: 0.0276 - acc: 0.9930 - val_loss: 0.0274 - val_acc: 0.9914\n",
      "Epoch 4/50\n",
      "19951/19951 [==============================] - 2s 122us/step - loss: 0.0236 - acc: 0.9936 - val_loss: 0.0259 - val_acc: 0.9918\n",
      "Epoch 5/50\n",
      "19951/19951 [==============================] - 2s 123us/step - loss: 0.0215 - acc: 0.9940 - val_loss: 0.0251 - val_acc: 0.9924\n",
      "Epoch 6/50\n",
      "19951/19951 [==============================] - 2s 121us/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 7/50\n",
      "19951/19951 [==============================] - 2s 125us/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.0263 - val_acc: 0.9914\n",
      "Epoch 8/50\n",
      "19951/19951 [==============================] - 2s 103us/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 9/50\n",
      "19951/19951 [==============================] - 2s 119us/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0243 - val_acc: 0.9920\n",
      "Epoch 10/50\n",
      "19951/19951 [==============================] - 2s 109us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0244 - val_acc: 0.9920\n",
      "Epoch 11/50\n",
      "19951/19951 [==============================] - 2s 109us/step - loss: 0.0157 - acc: 0.9956 - val_loss: 0.0251 - val_acc: 0.9922\n",
      "Epoch 12/50\n",
      "19951/19951 [==============================] - 2s 124us/step - loss: 0.0171 - acc: 0.9945 - val_loss: 0.0243 - val_acc: 0.9920\n",
      "Epoch 13/50\n",
      "19951/19951 [==============================] - 2s 112us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 14/50\n",
      "19951/19951 [==============================] - 2s 109us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 15/50\n",
      "19951/19951 [==============================] - 2s 110us/step - loss: 0.0160 - acc: 0.9949 - val_loss: 0.0247 - val_acc: 0.9920\n",
      "Epoch 16/50\n",
      "12160/19951 [=================>............] - ETA: 0s - loss: 0.0139 - acc: 0.9958"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "fit_callback = [EarlyStopping(monitor='val_loss',patience=8)]\n",
    "\n",
    "model_hist = model.fit(train_data, train_labels,\n",
    "                       batch_size=128,epochs=50,\n",
    "                       validation_split = 0.2,\n",
    "                       verbose=1,\n",
    "                       callbacks=fit_callback\n",
    "          )\n",
    "\n",
    "# show_history(model_hist.history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath = 'log/'+model_name\n",
    "    \n",
    "model.save(logpath+'.h5')\n",
    "with open(logpath+'_hist.txt','w') as f:\n",
    "    f.write(str(model_hist.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_acc': [0.9869687251310494, 0.98757016840417, 0.9883720930232558, 0.9881716118684843, 0.9891740178335353, 0.98757016840417, 0.989374498797113, 0.9891740178335353, 0.9887730553327987, 0.9893744989883068, 0.9899759424526211, 0.9895749799518845, 0.9893744989883068, 0.9893744989883068, 0.9893744989883068, 0.9885725741780272, 0.9899759422614274, 0.9887730555239924], 'loss': [0.15714101455640772, 0.05485500113893971, 0.04621594611385981, 0.04136499901642973, 0.037769564398633534, 0.03737628129376492, 0.037246065430220285, 0.03441768774026038, 0.03754797951899449, 0.031912068038294536, 0.03466382754143079, 0.033351589602698184, 0.03154747290396253, 0.03286503169596536, 0.03238750091488708, 0.03296497133738098, 0.03287086671958722, 0.03154833810669555], 'val_loss': [0.046750625104022774, 0.03544169541750082, 0.032515743869837035, 0.033649612694632174, 0.031541235128054644, 0.035015962728909375, 0.032678879928904336, 0.03142663651409633, 0.033720982277432775, 0.031025969237387898, 0.03152914975307517, 0.033403273001193716, 0.032222955104534205, 0.032025848115766725, 0.032755157940908254, 0.03619079581747891, 0.032811991652322944, 0.03468926388056353], 'acc': [0.9384993234019394, 0.9806024760663626, 0.983910580983013, 0.984111072156586, 0.9870683174074506, 0.9863164754243944, 0.9857150018439246, 0.9869179489749887, 0.9873690542723743, 0.989223597874397, 0.9876697909879204, 0.9886221242043005, 0.9888727382086111, 0.9884717558614652, 0.9890732294419351, 0.9874191770732363, 0.9885218786025763, 0.9884717558315897]}\n"
     ]
    }
   ],
   "source": [
    "## 查看 history\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def read_history_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    hist = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return hist\n",
    "    \n",
    "histfile = 'log/'+model_name+'_hist.txt'\n",
    "hist = read_history_from_file(histfile)\n",
    "print(hist)\n",
    "\n",
    "# title_name = model_name\n",
    "# show_history(hist, title_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用拟合后的模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 65us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测结果写入kaggle sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"pre-test\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv(model_name+'_pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\t\"PRE-X\" [label=\"Xception|{input:|output:}|{(299, 299, 3)|(2048)}\"]\n",
      "\t\"PRE-I\" [label=\"InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tIN -> \"PRE-X\"\n",
      "\tIN -> \"PRE-I\"\n",
      "\tL3 [label=\"Merge|{input:|output:}|{(2048,3)|2048*3=6144}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\t\"PRE-X\" -> L3\n",
      "\t\"PRE-I\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{6144|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model-table.gv.pdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.node('PRE-I', 'InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "dot.edge('IN', 'PRE-X')\n",
    "dot.edge('IN', 'PRE-I')\n",
    "# dot.edges(['AB', 'AL'])\n",
    "# dot.edge('PRE-R', 'PRE-X', constraint='false')\n",
    "\n",
    "dot.node('L3', 'Merge|{input:|output:}|{(2048,3)|2048*3=6144}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "dot.edge('PRE-X', 'L3')\n",
    "dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{6144|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('model-table.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  单模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tL3 [label=\"Input|{input:|output:}|{(2048,1)|2048}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{6144|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sigle-model.gv.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "#dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "#dot.node('PRE-I', 'InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "#dot.edge('IN', 'PRE-X')\n",
    "# dot.edge('IN', 'PRE-I')\n",
    "\n",
    "dot.node('L3', 'Input|{input:|output:}|{(2048,1)|2048}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "# dot.edge('PRE-X', 'L3')\n",
    "# dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{6144|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('sigle-model.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
