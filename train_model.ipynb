{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use composite model\n",
      "model name: Composite_Model\n"
     ]
    }
   ],
   "source": [
    "#pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', 'Xception':'Xception_pre_out.h5', 'InceptionV3':'InceptionV3_pre_out.h5'}\n",
    "pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', \n",
    "                      'Xception':'Xception_pre_out.h5', \n",
    "                      'InceptionResNetV2':'InceptionResNetV2_pre_out.h5'}\n",
    "\n",
    "composite_model = True\n",
    "single_model = 'InceptionResNetV2'\n",
    "\n",
    "# check training parameter\n",
    "if not composite_model and single_model not in pre_features_files:\n",
    "    print(\"%s not found in pre-trained models\" %single_model)\n",
    "else:\n",
    "    if composite_model:\n",
    "        print(\"will use composite model\")\n",
    "    else:\n",
    "        print(\"will use %s model\" %single_model)\n",
    "        \n",
    "if composite_model:\n",
    "    model_name = 'Composite_Model'\n",
    "else:\n",
    "    model_name = single_model\n",
    "    \n",
    "print('model name:', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def show_history(hist, title_name):\n",
    "    # epoch as x-axis \n",
    "    epochs = range(len(hist['acc']))\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ## left scale: acc, val_acc\n",
    "    # acc\n",
    "    line_acc = ax1.plot(epochs, hist['acc'], 'r', label='acc')\n",
    "    # loss\n",
    "#     ax1.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    # val_acc\n",
    "    line_val_acc = ax1.plot(epochs, hist['val_acc'], 'b', label='val_acc')\n",
    "    # val_loss\n",
    "#     ax1.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    \n",
    "    ax1.set(xlabel='epochs', ylabel='acc',title=title_name)\n",
    "    \n",
    "    ## right scale: loss, val_loss\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('loss', color=color)  # we already handled the x-label with ax1\n",
    "    line_loss = ax2.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    line_val_loss = ax2.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#     ax1.legend(loc='upper right', fancybox=True,)\n",
    "#     ax2.legend(loc='lower right', fancybox=True)\n",
    "    \n",
    "    ax1.grid(True)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    acc_patch = mpatches.Patch(color='r', label='acc',linestyle='-')\n",
    "    val_acc_patch = mpatches.Patch(color='b', label='val-acc')\n",
    "    loss_patch = mpatches.Patch(color='g', label='loss')\n",
    "    val_loss_patch = mpatches.Patch(color='k', label='val-loss')\n",
    "    fig.legend(handles=[acc_patch, val_acc_patch, loss_patch, val_loss_patch],\n",
    "               ncol=4, loc='lower center',\n",
    "               mode=\"expand\", borderaxespad=0.,)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 5632)\n",
      "train_data: [[0.20157795 0.33358407 0.09585248 ... 0.02308517 0.         0.23087822]\n",
      " [0.10468061 0.00802733 0.02267138 ... 0.         0.02877969 0.04635844]\n",
      " [0.09410941 0.06788639 0.11360098 ... 0.02613068 0.47964153 0.61643195]\n",
      " [0.20197937 0.02258976 0.04261705 ... 0.         0.02235488 0.55988157]\n",
      " [0.29612273 0.52252316 0.063084   ... 0.08623303 0.14639798 0.60639906]]\n",
      "test shape: (25000, 5632)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(66)\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# #------- single pre-trained model\n",
    "if not composite_model:\n",
    "    with h5py.File(pre_features_files[single_model] , 'r') as h:\n",
    "        train_data.append(np.array(h['train']))\n",
    "        train_labels = np.array(h['label'])\n",
    "        test_data.append(np.array(h['test']))\n",
    "else:#-------- composite model\n",
    "    for modelname in pre_features_files:\n",
    "        with h5py.File(pre_features_files[modelname]) as h:\n",
    "            train_data.append(np.array(h['train']))\n",
    "            train_labels = np.array(h['label'])\n",
    "            test_data.append(np.array(h['test']))\n",
    "\n",
    "train_data = np.concatenate(train_data, axis=1)\n",
    "test_data = np.concatenate(test_data, axis=1)\n",
    "\n",
    "print(\"train shape:\",train_data.shape)\n",
    "print(\"train_data:\",train_data[:5])\n",
    "\n",
    "print(\"test shape:\",train_data.shape)\n",
    "# 预存的X_train, y_train是按顺序存放的，前12500是猫，后12500是狗, 这里打乱顺序，使之随机存放\n",
    "# Note: 打乱的是存放存放顺序，并不改变 X_train , y_train的对应关系\n",
    "train_data, train_labels = shuffle(train_data, train_labels)\n",
    "\n",
    "train_data_unclean = train_data\n",
    "train_labels_unclean = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剔除train中的异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "## outliers list\n",
    "train_outliers=['cat.10636.jpg', 'dog.10161.jpg', 'dog.2614.jpg', 'cat.7564.jpg', 'cat.7377.jpg', 'cat.3216.jpg', 'dog.2422.jpg', 'dog.11266.jpg', 'cat.5071.jpg', 'cat.6345.jpg', 'dog.1773.jpg', 'cat.8456.jpg', 'dog.10190.jpg', 'cat.8921.jpg', 'cat.10029.jpg', 'cat.3004.jpg', 'cat.9171.jpg', 'dog.4218.jpg', 'cat.5418.jpg', 'cat.5974.jpg', 'dog.1895.jpg', 'cat.2520.jpg', 'cat.9983.jpg', 'dog.4507.jpg', 'cat.4338.jpg', 'dog.9188.jpg', 'dog.9517.jpg', 'cat.4308.jpg', 'dog.6475.jpg', 'cat.10365.jpg', 'dog.10237.jpg', 'cat.8470.jpg', 'dog.1625.jpg', 'dog.4367.jpg', 'dog.11299.jpg', 'cat.10536.jpg', 'cat.5351.jpg', 'dog.5604.jpg', 'dog.10747.jpg', 'cat.7464.jpg', 'dog.1259.jpg', 'cat.4688.jpg', 'cat.12272.jpg', 'dog.3889.jpg', 'dog.8898.jpg', 'dog.7706.jpg', 'cat.10712.jpg', 'cat.11184.jpg', 'cat.12476.jpg', 'cat.7968.jpg', 'dog.8736.jpg', 'dog.6725.jpg', 'cat.1139.jpg', 'cat.6348.jpg', 'dog.12376.jpg', 'dog.2339.jpg', 'dog.11437.jpg', 'dog.10801.jpg', 'cat.12424.jpg', 'dog.1194.jpg', 'dog.7076.jpg', 'cat.11039.jpg', 'cat.3672.jpg', 'cat.2939.jpg']\n",
    "\n",
    "train_outliers.remove('cat.1139.jpg')\n",
    "train_outliers.remove('cat.3004.jpg')\n",
    "train_outliers.remove('dog.7706.jpg')\n",
    "\n",
    "print(len(train_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## create train_generator\n",
    "# import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(\"pre-train\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939, 5632)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outliers_index = [i for i,fn in enumerate(train_generator.filenames) if fn.split('/')[1] in train_outliers]\n",
    "train_data = np.array([x for i,x in enumerate(train_data_unclean) if i not in outliers_index])\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.array([x for i,x in enumerate(train_labels_unclean) if i not in outliers_index])\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(666)\n",
    "\n",
    "input_tensor = Input(train_data.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在pre-train features上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19951 samples, validate on 4988 samples\n",
      "Epoch 1/50\n",
      "19951/19951 [==============================] - 5s 248us/step - loss: 0.0679 - acc: 0.9784 - val_loss: 0.0202 - val_acc: 0.9948\n",
      "Epoch 2/50\n",
      "19951/19951 [==============================] - 3s 154us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0173 - val_acc: 0.9956\n",
      "Epoch 3/50\n",
      "19951/19951 [==============================] - 2s 116us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0172 - val_acc: 0.9948\n",
      "Epoch 4/50\n",
      "19951/19951 [==============================] - 2s 115us/step - loss: 0.0134 - acc: 0.9959 - val_loss: 0.0166 - val_acc: 0.9954\n",
      "Epoch 5/50\n",
      "19951/19951 [==============================] - 2s 122us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0167 - val_acc: 0.9950\n",
      "Epoch 6/50\n",
      "19951/19951 [==============================] - 2s 102us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0175 - val_acc: 0.9948\n",
      "Epoch 7/50\n",
      "19951/19951 [==============================] - 2s 100us/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0170 - val_acc: 0.9946\n",
      "Epoch 8/50\n",
      "19951/19951 [==============================] - 2s 100us/step - loss: 0.0100 - acc: 0.9971 - val_loss: 0.0169 - val_acc: 0.9948\n",
      "Epoch 9/50\n",
      "19951/19951 [==============================] - 2s 106us/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 10/50\n",
      "19951/19951 [==============================] - 2s 118us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 11/50\n",
      "19951/19951 [==============================] - 2s 123us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 12/50\n",
      "19951/19951 [==============================] - 2s 114us/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0180 - val_acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "fit_callback = [EarlyStopping(monitor='val_loss',patience=8)]\n",
    "\n",
    "model_hist = model.fit(train_data, train_labels,\n",
    "                       batch_size=128,epochs=50,\n",
    "                       validation_split = 0.2,\n",
    "                       verbose=1,\n",
    "                       callbacks=fit_callback\n",
    "          )\n",
    "\n",
    "# show_history(model_hist.history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath = 'log/'+model_name\n",
    "    \n",
    "model.save(logpath+'.h5')\n",
    "with open(logpath+'_hist.txt','w') as f:\n",
    "    f.write(str(model_hist.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': [0.9783970728583051, 0.994185755099995, 0.9952884567189615, 0.9959400531600444, 0.9961405443336173, 0.9962909127362037, 0.9964412811686656, 0.9970928775499975, 0.9976442283893563, 0.9972432460422104, 0.9972432459525838, 0.9975941055586186], 'val_loss': [0.020172176362816676, 0.017299368872987622, 0.017155657837551262, 0.016631385074359302, 0.01668103973387943, 0.017505276962777164, 0.01704516221560783, 0.01691301576322678, 0.018814419511983465, 0.01729632291753135, 0.017538181277934488, 0.017977078221200607], 'loss': [0.06792696627680087, 0.017660013280562825, 0.01431360328058857, 0.013437713635261481, 0.012537521183459757, 0.011574997489127414, 0.01105098085667751, 0.01001789008965354, 0.00860160013974388, 0.009010299239207745, 0.009634733285453329, 0.007939572146032713], 'val_acc': [0.9947874899759422, 0.995589414595028, 0.9947874899759422, 0.9953889334402566, 0.9949879711307137, 0.9947874899759422, 0.9945870088211708, 0.9947874899759422, 0.9945870088211708, 0.9949879711307137, 0.9949879711307137, 0.9947874899759422]}\n"
     ]
    }
   ],
   "source": [
    "## 查看 history\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def read_history_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    hist = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return hist\n",
    "    \n",
    "histfile = 'log/'+model_name+'_hist.txt'\n",
    "hist = read_history_from_file(histfile)\n",
    "print(hist)\n",
    "\n",
    "# title_name = model_name\n",
    "# show_history(hist, title_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用拟合后的模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 54us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测结果写入kaggle sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"pre-test\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv(model_name+'_pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化\n",
    "\n",
    "#### 组合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\t\"PRE-X\" [label=\"Xception|{input:|output:}|{(299, 299, 3)|(2048)}\"]\n",
      "\t\"PRE-I\" [label=\"InceptionResNetV2|{input:|output:}|{(299, 299, 3)|(1536)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tIN -> \"PRE-X\"\n",
      "\tIN -> \"PRE-I\"\n",
      "\tL3 [label=\"Merge|{input:|output:}|{(3,2048+2048+1536=5632)|5632}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\t\"PRE-X\" -> L3\n",
      "\t\"PRE-I\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{5632|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model-table.gv.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.node('PRE-I', 'InceptionResNetV2|{input:|output:}|{(299, 299, 3)|(1536)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "dot.edge('IN', 'PRE-X')\n",
    "dot.edge('IN', 'PRE-I')\n",
    "\n",
    "dot.node('L3', 'Merge|{input:|output:}|{(3,2048+2048+1536=5632)|5632}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "dot.edge('PRE-X', 'L3')\n",
    "dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{5632|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('model-table.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  单模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tL3 [label=\"Input|{input:|output:}|{(2048,1)|2048}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{2048|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sigle-model.gv.pdf'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "#dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "#dot.node('PRE-I', 'InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "#dot.edge('IN', 'PRE-X')\n",
    "# dot.edge('IN', 'PRE-I')\n",
    "\n",
    "dot.node('L3', 'Input|{input:|output:}|{(2048,1)|2048}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "# dot.edge('PRE-X', 'L3')\n",
    "# dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{2048|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('sigle-model.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
