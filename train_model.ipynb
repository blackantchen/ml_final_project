{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use composite model\n",
      "model name: Composite_Model\n"
     ]
    }
   ],
   "source": [
    "#pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', 'Xception':'Xception_pre_out.h5', 'InceptionV3':'InceptionV3_pre_out.h5'}\n",
    "pre_features_files = {'ResNet50':'ResNet50_pre_out.h5', \n",
    "                      'Xception':'Xception_pre_out.h5', \n",
    "                      'InceptionResNetV2':'InceptionResNetV2_pre_out.h5'}\n",
    "\n",
    "composite_model = True\n",
    "single_model = 'Xception'\n",
    "\n",
    "# check training parameter\n",
    "if not composite_model and single_model not in pre_features_files:\n",
    "    print(\"%s not found in pre-trained models\" %single_model)\n",
    "else:\n",
    "    if composite_model:\n",
    "        print(\"will use composite model\")\n",
    "    else:\n",
    "        print(\"will use %s model\" %single_model)\n",
    "        \n",
    "if composite_model:\n",
    "    model_name = 'Composite_Model'\n",
    "else:\n",
    "    model_name = single_model\n",
    "    \n",
    "print('model name:', model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def show_history(hist, title_name):\n",
    "    # epoch as x-axis \n",
    "    epochs = range(len(hist['acc']))\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ## left scale: acc, val_acc\n",
    "    # acc\n",
    "    line_acc = ax1.plot(epochs, hist['acc'], 'r', label='acc')\n",
    "    # loss\n",
    "#     ax1.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    # val_acc\n",
    "    line_val_acc = ax1.plot(epochs, hist['val_acc'], 'b', label='val_acc')\n",
    "    # val_loss\n",
    "#     ax1.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    \n",
    "    ax1.set(xlabel='epochs', ylabel='acc',title=title_name)\n",
    "    \n",
    "    ## right scale: loss, val_loss\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('loss', color=color)  # we already handled the x-label with ax1\n",
    "    line_loss = ax2.plot(epochs, hist['loss'], 'g', label='loss')\n",
    "    line_val_loss = ax2.plot(epochs, hist['val_loss'], 'k', label='val_loss')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#     ax1.legend(loc='upper right', fancybox=True,)\n",
    "#     ax2.legend(loc='lower right', fancybox=True)\n",
    "    \n",
    "    ax1.grid(True)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    acc_patch = mpatches.Patch(color='r', label='acc',linestyle='-')\n",
    "    val_acc_patch = mpatches.Patch(color='b', label='val-acc')\n",
    "    loss_patch = mpatches.Patch(color='g', label='loss')\n",
    "    val_loss_patch = mpatches.Patch(color='k', label='val-loss')\n",
    "    fig.legend(handles=[acc_patch, val_acc_patch, loss_patch, val_loss_patch],\n",
    "               ncol=4, loc='lower center',\n",
    "               mode=\"expand\", borderaxespad=0.,)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 5632)\n",
      "train_data: [[0.06419943 0.5325118  0.61818767 ... 1.4656898  0.10975234 0.13627772]\n",
      " [0.01955884 0.2614151  0.00553378 ... 0.01356897 0.04284026 0.        ]\n",
      " [0.0658308  0.13139124 0.12781699 ... 0.21625854 0.13916504 0.30605924]\n",
      " [0.25487077 0.24022049 0.15445104 ... 0.0120421  0.93518245 0.22036156]\n",
      " [0.03490764 0.2764068  0.12088037 ... 0.30616122 0.758728   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(66)\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# #------- single pre-trained model\n",
    "if not composite_model:\n",
    "    with h5py.File(pre_features_files[single_model] , 'r') as h:\n",
    "        train_data.append(np.array(h['train']))\n",
    "        train_labels = np.array(h['label'])\n",
    "        test_data.append(np.array(h['test']))\n",
    "else:#-------- composite model\n",
    "    for modelname in pre_features_files:\n",
    "        with h5py.File(pre_features_files[modelname]) as h:\n",
    "            train_data.append(np.array(h['train']))\n",
    "            train_labels = np.array(h['label'])\n",
    "            test_data.append(np.array(h['test']))\n",
    "\n",
    "train_data = np.concatenate(train_data, axis=1)\n",
    "test_data = np.concatenate(test_data, axis=1)\n",
    "\n",
    "print(\"train shape:\",train_data.shape)\n",
    "print(\"train_data:\",train_data[:5])\n",
    "# 预存的X_train, y_train是按顺序存放的，前12500是猫，后12500是狗, 这里打乱顺序，使之随机存放\n",
    "# Note: 打乱的是存放存放顺序，并不改变 X_train , y_train的对应关系\n",
    "train_data, train_labels = shuffle(train_data, train_labels)\n",
    "\n",
    "train_data_unclean = train_data\n",
    "train_labels_unclean = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 剔除train中的异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "## outliers list\n",
    "train_outliers=['cat.10636.jpg', 'dog.10161.jpg', 'dog.2614.jpg', 'cat.7564.jpg', 'cat.7377.jpg', 'cat.3216.jpg', 'dog.2422.jpg', 'dog.11266.jpg', 'cat.5071.jpg', 'cat.6345.jpg', 'dog.1773.jpg', 'cat.8456.jpg', 'dog.10190.jpg', 'cat.8921.jpg', 'cat.10029.jpg', 'cat.3004.jpg', 'cat.9171.jpg', 'dog.4218.jpg', 'cat.5418.jpg', 'cat.5974.jpg', 'dog.1895.jpg', 'cat.2520.jpg', 'cat.9983.jpg', 'dog.4507.jpg', 'cat.4338.jpg', 'dog.9188.jpg', 'dog.9517.jpg', 'cat.4308.jpg', 'dog.6475.jpg', 'cat.10365.jpg', 'dog.10237.jpg', 'cat.8470.jpg', 'dog.1625.jpg', 'dog.4367.jpg', 'dog.11299.jpg', 'cat.10536.jpg', 'cat.5351.jpg', 'dog.5604.jpg', 'dog.10747.jpg', 'cat.7464.jpg', 'dog.1259.jpg', 'cat.4688.jpg', 'cat.12272.jpg', 'dog.3889.jpg', 'dog.8898.jpg', 'dog.7706.jpg', 'cat.10712.jpg', 'cat.11184.jpg', 'cat.12476.jpg', 'cat.7968.jpg', 'dog.8736.jpg', 'dog.6725.jpg', 'cat.1139.jpg', 'cat.6348.jpg', 'dog.12376.jpg', 'dog.2339.jpg', 'dog.11437.jpg', 'dog.10801.jpg', 'cat.12424.jpg', 'dog.1194.jpg', 'dog.7076.jpg', 'cat.11039.jpg', 'cat.3672.jpg', 'cat.2939.jpg']\n",
    "\n",
    "train_outliers.remove('cat.1139.jpg')\n",
    "train_outliers.remove('cat.3004.jpg')\n",
    "train_outliers.remove('dog.7706.jpg')\n",
    "\n",
    "print(len(train_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## create train_generator\n",
    "# import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(\"pre-train\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939, 5632)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outliers_index = [i for i,fn in enumerate(train_generator.filenames) if fn.split('/')[1] in train_outliers]\n",
    "train_data = np.array([x for i,x in enumerate(train_data_unclean) if i not in outliers_index])\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24939,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.array([x for i,x in enumerate(train_labels_unclean) if i not in outliers_index])\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(666)\n",
    "\n",
    "input_tensor = Input(train_data.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在pre-train features上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19951 samples, validate on 4988 samples\n",
      "Epoch 1/50\n",
      "19951/19951 [==============================] - 5s 260us/step - loss: 0.0638 - acc: 0.9806 - val_loss: 0.0209 - val_acc: 0.9940\n",
      "Epoch 2/50\n",
      "19951/19951 [==============================] - 5s 243us/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0157 - val_acc: 0.9950\n",
      "Epoch 3/50\n",
      "19951/19951 [==============================] - 5s 237us/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "Epoch 4/50\n",
      "19951/19951 [==============================] - 5s 260us/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0153 - val_acc: 0.9954\n",
      "Epoch 5/50\n",
      "19951/19951 [==============================] - 5s 261us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.0154 - val_acc: 0.9952\n",
      "Epoch 6/50\n",
      "19951/19951 [==============================] - 7s 348us/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0171 - val_acc: 0.9948\n",
      "Epoch 7/50\n",
      "19951/19951 [==============================] - 10s 498us/step - loss: 0.0115 - acc: 0.9966 - val_loss: 0.0155 - val_acc: 0.9952\n",
      "Epoch 8/50\n",
      "19951/19951 [==============================] - 7s 357us/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0167 - val_acc: 0.9948\n",
      "Epoch 9/50\n",
      "19951/19951 [==============================] - 8s 398us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0161 - val_acc: 0.9950\n",
      "Epoch 10/50\n",
      "19951/19951 [==============================] - 6s 293us/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0158 - val_acc: 0.9948\n",
      "Epoch 11/50\n",
      "19951/19951 [==============================] - 6s 313us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0171 - val_acc: 0.9950\n",
      "Epoch 12/50\n",
      "19951/19951 [==============================] - 6s 294us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0166 - val_acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "fit_callback = [EarlyStopping(monitor='val_loss',patience=8)]\n",
    "\n",
    "model_hist = model.fit(train_data, train_labels,\n",
    "                       batch_size=128,epochs=50,\n",
    "                       validation_split = 0.2,\n",
    "                       verbose=1,\n",
    "                       callbacks=fit_callback\n",
    "          )\n",
    "\n",
    "# show_history(model_hist.history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath = 'log/'+model_name\n",
    "    \n",
    "model.save(logpath+'.h5')\n",
    "with open(logpath+'_hist.txt','w') as f:\n",
    "    f.write(str(model_hist.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.02090158480060464, 0.015739635599862245, 0.01577814605046712, 0.015278635505861704, 0.01541077817581839, 0.017059143748412203, 0.015522938660841134, 0.016660122021602553, 0.016118541233683694, 0.01580147857799433, 0.017058762688855936, 0.01656070227847519], 'val_acc': [0.9939855653568564, 0.9949879711307137, 0.9959903769045709, 0.9953889334402566, 0.9951884522854851, 0.9947874899759422, 0.9951884522854851, 0.9947874899759422, 0.9949879711307137, 0.9947874899759422, 0.9949879711307137, 0.9943865276663993], 'loss': [0.06383925110018049, 0.01824372701330676, 0.014378739819825959, 0.01339605523489106, 0.012686219220756773, 0.01116332047760881, 0.01147974113538405, 0.010360054647303794, 0.00980828053980687, 0.009681007056197115, 0.00885186465080487, 0.008853173605430704], 'acc': [0.980552353295376, 0.9944363691043056, 0.9952383339180993, 0.9963410355669413, 0.9962909127362037, 0.9968422635755625, 0.9965916496011274, 0.9966417723422385, 0.9968923863465491, 0.9971931231815973, 0.997343491554308, 0.9969926319482733]}\n"
     ]
    }
   ],
   "source": [
    "## 查看 history\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def read_history_from_file(filename):\n",
    "    f = open(filename,'r')\n",
    "    rdbuf = f.read()\n",
    "    hist = eval(rdbuf)\n",
    "    f.close()\n",
    "    \n",
    "    return hist\n",
    "    \n",
    "histfile = 'log/'+model_name+'_hist.txt'\n",
    "hist = read_history_from_file(histfile)\n",
    "print(hist)\n",
    "\n",
    "# title_name = model_name\n",
    "# show_history(hist, title_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用拟合后的模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 67us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测结果写入kaggle sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"pre-test\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv(model_name+'_pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\t\"PRE-X\" [label=\"Xception|{input:|output:}|{(299, 299, 3)|(2048)}\"]\n",
      "\t\"PRE-I\" [label=\"InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tIN -> \"PRE-X\"\n",
      "\tIN -> \"PRE-I\"\n",
      "\tL3 [label=\"Merge|{input:|output:}|{(2048,3)|2048*3=6144}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\t\"PRE-X\" -> L3\n",
      "\t\"PRE-I\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{6144|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model-table.gv.pdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.node('PRE-I', 'InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "dot.edge('IN', 'PRE-X')\n",
    "dot.edge('IN', 'PRE-I')\n",
    "# dot.edges(['AB', 'AL'])\n",
    "# dot.edge('PRE-R', 'PRE-X', constraint='false')\n",
    "\n",
    "dot.node('L3', 'Merge|{input:|output:}|{(2048,3)|2048*3=6144}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "dot.edge('PRE-X', 'L3')\n",
    "dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{6144|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('model-table.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  单模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// The Model Chart\n",
      "digraph {\n",
      "\tnode [shape=record]\n",
      "\tIN [label=\"Input|images\"]\n",
      "\t\"PRE-R\" [label=\"ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}\"]\n",
      "\tIN -> \"PRE-R\"\n",
      "\tL3 [label=\"Input|{input:|output:}|{(2048,1)|2048}\"]\n",
      "\t\"PRE-R\" -> L3\n",
      "\tL4 [label=\"Dropout|Rate:|0.5\"]\n",
      "\tL5 [label=\"Output|{input:|output:}|{2048|1}\"]\n",
      "\tL3 -> L4\n",
      "\tL4 -> L5\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sigle-model.gv.pdf'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='The Model Chart')\n",
    "\n",
    "dot.attr('node',shape='record')\n",
    "\n",
    "dot.node('IN', 'Input|images')\n",
    "dot.node('PRE-R', 'ResNet50|{input:|output:}|{(224, 224, 3)|(2048)}')\n",
    "#dot.node('PRE-X', 'Xception|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "#dot.node('PRE-I', 'InceptionV3|{input:|output:}|{(299, 299, 3)|(2048)}')\n",
    "dot.edge('IN', 'PRE-R')\n",
    "#dot.edge('IN', 'PRE-X')\n",
    "# dot.edge('IN', 'PRE-I')\n",
    "\n",
    "dot.node('L3', 'Input|{input:|output:}|{(2048,1)|2048}')\n",
    "dot.edge('PRE-R', 'L3')\n",
    "# dot.edge('PRE-X', 'L3')\n",
    "# dot.edge('PRE-I', 'L3')\n",
    "\n",
    "dot.node('L4', 'Dropout|Rate:|0.5')\n",
    "dot.node('L5', 'Output|{input:|output:}|{2048|1}')\n",
    "dot.edge('L3', 'L4')\n",
    "dot.edge('L4', 'L5')\n",
    "\n",
    "print(dot.source)\n",
    "dot.render('sigle-model.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
